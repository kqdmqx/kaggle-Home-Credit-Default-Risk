{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import addict\n",
    "import lightgbm as lgb\n",
    "\n",
    "def save_dataframe(path, dataframe):\n",
    "    np.save(path + \".data\", dataframe.values)\n",
    "    np.save(path + \".header\", dataframe.columns)\n",
    "\n",
    "\n",
    "def load_dataframe(path):\n",
    "    data = np.load(path + \".data.npy\")\n",
    "    header = np.load(path + \".header.npy\")\n",
    "    return pd.DataFrame(data=data, columns=header)\n",
    "\n",
    "\n",
    "def save_dataframe32(path, dataframe, keep=[]):\n",
    "    col64 = [col_ for col_ in dataframe.columns if col_ in keep]\n",
    "    col32 = [col_ for col_ in dataframe.columns if col_ not in keep]\n",
    "    dataframe64 = dataframe[col64]\n",
    "    dataframe32 = dataframe[col32]\n",
    "    np.save(path + \".data64\", dataframe64.values)\n",
    "    np.save(path + \".header64\", col64)\n",
    "    np.save(path + \".data32\", dataframe32.values.astype(np.float32))\n",
    "    np.save(path + \".header32\", col32)\n",
    "\n",
    "\n",
    "def load_dataframe32(path, nrows=None):\n",
    "    path_data32 = path + \".data32.npy\"\n",
    "    path_header32 = path + \".header32.npy\"\n",
    "    path_data64 = path + \".data64.npy\"\n",
    "    path_header64 = path + \".header64.npy\"\n",
    "    result = pd.DataFrame()\n",
    "    if os.path.exists(path_data32):\n",
    "        data32 = np.load(path_data32)\n",
    "        header32 = np.load(path_header32)\n",
    "        df32 = pd.DataFrame(data=data32, columns=header32)\n",
    "        result = pd.concat([result, df32], axis=1)\n",
    "    if os.path.exists(path_data64):\n",
    "        data64 = np.load(path_data64)\n",
    "        header64 = np.load(path_header64)\n",
    "        df64 = pd.DataFrame(data=data64, columns=header64)\n",
    "        result = pd.concat([result, df64], axis=1)\n",
    "    if nrows and nrows > 0:\n",
    "        return result.head(nrows)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\python3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature group & model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header(feature_name, length=4):\n",
    "    for char in \"0123456789\":\n",
    "        feature_name = feature_name.replace(char, \"\")\n",
    "    items = feature_name.split(\"_\")\n",
    "    if len(items) < length + 1:\n",
    "        return \"short\"\n",
    "    return \"_\".join(items[:length])\n",
    "\n",
    "def create_feature_info(features):\n",
    "    features_info = pd.DataFrame({\n",
    "        \"feature_idx\": np.arange(len(features)),\n",
    "        \"feature_name\": features\n",
    "    })\n",
    "\n",
    "    features_info[\"feature_header\"] = features_info.feature_name.apply(get_header)\n",
    "    features_info[\"group_size\"] = features_info.feature_header.map(features_info.feature_header.value_counts())\n",
    "    features_info.loc[features_info.group_size < 10, \"feature_header\"] = \"short\"\n",
    "    features_info[\"group_size\"] = features_info.feature_header.map(features_info.feature_header.value_counts())\n",
    "    return features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_scaler_stack(features_info):\n",
    "    return {key: StandardScaler() for key in features_info.feature_header.unique()}\n",
    "\n",
    "def create_feature_stack(feature_info):\n",
    "    return {key: list(features_info[features_info.feature_header == key].feature_name) for key in features_info.feature_header.unique()}\n",
    "\n",
    "def replace_nan(X):\n",
    "    X = X.copy()\n",
    "    X[np.isnan(X)] = 0\n",
    "    X[X == np.Inf] = X[X != np.Inf].max()\n",
    "    X[X == -np.Inf] = X[X != -np.Inf].min()\n",
    "    # print(X.shape, X.max(), X.min())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def less_ftr(input_dim):\n",
    "    return int(np.log(input_dim) * np.sqrt(input_dim))\n",
    "\n",
    "def create_model(feature_stack):\n",
    "    input_lyr = [Input(shape=[len(ftrs_)], name=key_) for key_, ftrs_ in feature_stack.items()]\n",
    "    dense0_lyr = [Dense(less_ftr(len(ftrs_)), activation=\"relu\")(input_lyr[i]) for i, (key_, ftrs_) in enumerate(feature_stack.items())]\n",
    "    main0_lyr = concatenate(dense0_lyr)\n",
    "    drop0_lyr = Dropout(.75)(main0_lyr)\n",
    "    main1_lyr = Dense(128, activation=\"relu\")(drop0_lyr)\n",
    "    output = Dense(1, activation=\"sigmoid\")(main1_lyr)\n",
    "    model = Model(input_lyr, output)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "features = list(np.load('./neptune-features/features_246008_1174_0.npy'))\n",
    "features_info = create_feature_info(features)\n",
    "features_stack = create_feature_stack(features_info)\n",
    "create_model_fixed = partial(create_model, features_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "short (InputLayer)              (None, 226)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NAME_EDUCATION_TYPE_CODE (Input (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NAME_FAMILY_STATUS_NAME (InputL (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NAME_FAMILY_STATUS_CODE (InputL (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NAME_EDUCATION_TYPE_OCCUPATION  (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bureau_SK_ID_CURR (InputLayer)  (None, 57)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "credit_card_balance_SK (InputLa (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "all_installment_installment_pai (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last__NUM_INSTALMENT (InputLaye (None, 54)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last__installment_paid (InputLa (None, 132)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last_by_fraction_NUM (InputLaye (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last_by_fraction_installment (I (None, 110)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last_loan_installment_paid (Inp (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "installments_payments_SK_ID (In (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "all_installment_SK_DPD (InputLa (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last__pos_cash (InputLayer)     (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "last__SK_DPD (InputLayer)       (None, 36)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "POS_CASH_balance_SK (InputLayer (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "previous_application_SK_ID (Inp (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 81)           18387       short[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 42)           3822        NAME_EDUCATION_TYPE_CODE[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 42)           3822        NAME_FAMILY_STATUS_NAME[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 42)           3822        NAME_FAMILY_STATUS_CODE[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 15)           375         NAME_EDUCATION_TYPE_OCCUPATION[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           1740        bureau_SK_ID_CURR[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 35)           2485        credit_card_balance_SK[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 14)           322         all_installment_installment_paid[\n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 29)           1595        last__NUM_INSTALMENT[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 56)           7448        last__installment_paid[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 25)           1150        last_by_fraction_NUM[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 49)           5439        last_by_fraction_installment[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 9)            135         last_loan_installment_paid[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 18)           558         installments_payments_SK_ID[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 8)            104         all_installment_SK_DPD[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 8)            104         last__pos_cash[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 21)           777         last__SK_DPD[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 10)           160         POS_CASH_balance_SK[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 25)           1150        previous_application_SK_ID[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 559)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 559)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 128)          71680       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            129         dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 125,204\n",
      "Trainable params: 125,204\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features = list(np.load('./neptune-features/features_246008_1174_0.npy'))\n",
    "features_info = create_feature_info(features)\n",
    "features_stack = create_feature_stack(features_info)\n",
    "\n",
    "model = create_model(features_stack)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roc_auc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # y_pred = self.model.predict_proba(self.x, verbose=0)\n",
    "        y_pred = self.model.predict(self.x, verbose=0)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n",
    "        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n",
    "\n",
    "        # y_pred_val = self.model.predict_proba(self.x_val, verbose=0)\n",
    "        y_pred_val = self.model.predict(self.x_val, verbose=0)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n",
    "\n",
    "        # print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./neptune-features/train_idx_0.npy ./neptune-features/valid_idx_0.npy\n",
      "(246008,) (61503,)\n",
      "./neptune-features/data_246008_1174_0 (246008, 1174)\n",
      "./neptune-features/data_61503_1174_1 (61503, 1174)\n",
      "./neptune-features/data_48744_1174_3 (48744, 1174)\n",
      "Epoch 00087: early stopping\n",
      "fold-0,auc:0.7866254609675846\n",
      "./neptune-features/train_idx_1.npy ./neptune-features/valid_idx_1.npy\n",
      "(246009,) (61502,)\n",
      "./neptune-features/data_246009_1174_4 (246009, 1174)\n",
      "./neptune-features/data_61502_1174_5 (61502, 1174)\n",
      "./neptune-features/data_48744_1174_7 (48744, 1174)\n",
      "Epoch 00073: early stopping\n",
      "fold-1,auc:0.7801398565450309\n",
      "./neptune-features/train_idx_2.npy ./neptune-features/valid_idx_2.npy\n",
      "(246009,) (61502,)\n",
      "./neptune-features/data_246009_1174_8 (246009, 1174)\n",
      "./neptune-features/data_61502_1174_9 (61502, 1174)\n",
      "./neptune-features/data_48744_1174_11 (48744, 1174)\n",
      "Epoch 00078: early stopping\n",
      "fold-2,auc:0.7802676912681713\n",
      "./neptune-features/train_idx_3.npy ./neptune-features/valid_idx_3.npy\n",
      "(246009,) (61502,)\n",
      "./neptune-features/data_246009_1174_12 (246009, 1174)\n",
      "./neptune-features/data_61502_1174_13 (61502, 1174)\n",
      "./neptune-features/data_48744_1174_15 (48744, 1174)\n",
      "Epoch 00050: early stopping\n",
      "fold-3,auc:0.7838391816098259\n",
      "./neptune-features/train_idx_4.npy ./neptune-features/valid_idx_4.npy\n",
      "(246009,) (61502,)\n",
      "./neptune-features/data_246009_1174_16 (246009, 1174)\n",
      "./neptune-features/data_61502_1174_17 (61502, 1174)\n",
      "./neptune-features/data_48744_1174_19 (48744, 1174)\n",
      "Epoch 00048: early stopping\n",
      "fold-4,auc:0.7811900203631054\n",
      "kfold-auc, avg:0.7824, std:0.0025\n"
     ]
    }
   ],
   "source": [
    "# nrows = 1000  \n",
    "nrows = None\n",
    "\n",
    "features = list(np.load('./neptune-features/features_246008_1174_0.npy'))\n",
    "features_info = create_feature_info(features)\n",
    "features_stack = create_feature_stack(features_info)\n",
    "\n",
    "train_app = load_dataframe32(\"./bindata/application_train\")\n",
    "auc_valid_stack = []\n",
    "pred_valid_stack = []\n",
    "pred_test_stack = []\n",
    "\n",
    "run = 0\n",
    "for i in range(5):\n",
    "    train_idx_fn = \"./neptune-features/train_idx_{}.npy\".format(i)\n",
    "    valid_idx_fn = \"./neptune-features/valid_idx_{}.npy\".format(i)\n",
    "\n",
    "    train_offset, valid_offset, test_offset = i * 4, i * 4 + 1, i * 4 + 3\n",
    "    \n",
    "    train_data_fn = \"./neptune-features/data_246009_1174_{}\".format(train_offset)\n",
    "    valid_data_fn = \"./neptune-features/data_61502_1174_{}\".format(valid_offset)\n",
    "    test_data_fn = \"./neptune-features/data_48744_1174_{}\".format(test_offset)\n",
    "    \n",
    "    if i == 0:\n",
    "        train_data_fn = train_data_fn.replace(\"246009\", \"246008\")\n",
    "        valid_data_fn = valid_data_fn.replace(\"61502\", \"61503\")\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    train_idx = np.load(train_idx_fn)\n",
    "    valid_idx = np.load(valid_idx_fn)\n",
    "    \n",
    "    if nrows:\n",
    "        train_idx, valid_idx = train_idx[:nrows].copy(), valid_idx[:nrows].copy()\n",
    "\n",
    "    train_data = load_dataframe32(train_data_fn, nrows)\n",
    "    valid_data = load_dataframe32(valid_data_fn, nrows)\n",
    "    test_data = load_dataframe32(test_data_fn, nrows)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    print(train_idx_fn, valid_idx_fn)\n",
    "    print(train_idx.shape, valid_idx.shape)\n",
    "    print(train_data_fn, train_data.shape)\n",
    "    print(valid_data_fn, valid_data.shape)\n",
    "    print(test_data_fn, test_data.shape)\n",
    "\n",
    "    scalar_stack = create_scaler_stack(features_info)\n",
    "    X_train_mult = {key: scalar_stack[key].fit_transform(replace_nan(train_data[items].values)) for key, items in features_stack.items()}\n",
    "    X_valid_mult = {key: scalar_stack[key].transform(replace_nan(valid_data[items].values)) for key, items in features_stack.items()}\n",
    "    X_test_mult = {key: scalar_stack[key].transform(replace_nan(test_data[items].values)) for key, items in features_stack.items()}\n",
    "\n",
    "    y_train = train_app.loc[train_idx].TARGET\n",
    "    y_valid = train_app.loc[valid_idx].TARGET\n",
    "    gc.collect()\n",
    "    \n",
    "    callbacks = [\n",
    "        roc_auc_callback(\n",
    "            training_data=(X_train_mult, y_train),\n",
    "            validation_data=(X_valid_mult, y_valid)\n",
    "        ),  # call this before EarlyStopping\n",
    "        EarlyStopping(monitor='norm_gini_val', patience=20, mode='max', verbose=1),\n",
    "        CSVLogger('keras-5fold-run-01-v1-epochs.log', separator=',', append=False),\n",
    "        ModelCheckpoint(\n",
    "            '025-keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check',\n",
    "            monitor='norm_gini_val', mode='max', # mode must be set to max or Keras will be confused\n",
    "            save_best_only=True,\n",
    "            verbose=0\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    np.random.seed(i)\n",
    "    # create_model(features_stack)\n",
    "    estimator = KerasClassifier(\n",
    "        build_fn=create_model_fixed,\n",
    "        epochs=5000,\n",
    "        batch_size=500,\n",
    "        validation_data=(X_valid_mult, y_valid),\n",
    "        verbose=0,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    estimator.fit(X_train_mult, y_train)\n",
    "    \n",
    "    del estimator\n",
    "    estimator = load_model('025-keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check')\n",
    "    \n",
    "    pred_valid = estimator.predict(X_valid_mult)\n",
    "    pred_valid_stack.append(pred_valid)\n",
    "    \n",
    "    auc = roc_auc_score(y_valid, pred_valid)\n",
    "    auc_valid_stack.append(auc)\n",
    "    print(\"fold-{},auc:{}\".format(i, auc))\n",
    "\n",
    "    pred_test = estimator.predict(X_test_mult)\n",
    "    pred_test_stack.append(pred_test)\n",
    "    \n",
    "    # break\n",
    "    \n",
    "print(\"kfold-auc, avg:{:.4}, std:{:.2}\".format(np.mean(auc_valid_stack), np.std(auc_valid_stack)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save oof & submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rank(predictions):\n",
    "    rank = (1 + pd.Series(predictions).rank().values) / (predictions.shape[0] + 1)\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.05016068],\n",
       "        [0.15800135],\n",
       "        [0.02343937],\n",
       "        ...,\n",
       "        [0.01606217],\n",
       "        [0.04193696],\n",
       "        [0.19432412]], dtype=float32), array([[0.06478611],\n",
       "        [0.17871755],\n",
       "        [0.05090065],\n",
       "        ...,\n",
       "        [0.01883596],\n",
       "        [0.04330845],\n",
       "        [0.2660742 ]], dtype=float32), array([[0.06531779],\n",
       "        [0.16371636],\n",
       "        [0.03275765],\n",
       "        ...,\n",
       "        [0.01619415],\n",
       "        [0.05017608],\n",
       "        [0.208277  ]], dtype=float32), array([[0.06209571],\n",
       "        [0.1564854 ],\n",
       "        [0.03136708],\n",
       "        ...,\n",
       "        [0.0152378 ],\n",
       "        [0.04115357],\n",
       "        [0.19500324]], dtype=float32), array([[0.05819519],\n",
       "        [0.15253244],\n",
       "        [0.02287433],\n",
       "        ...,\n",
       "        [0.01154504],\n",
       "        [0.03888638],\n",
       "        [0.19625895]], dtype=float32)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sample = pd.read_csv(\"./result/submission-022-blend08.csv\")\n",
    "pred_target = sum([calculate_rank(p_.reshape(pred_sample.shape[0])) for p_ in pred_test_stack]) / 5\n",
    "\n",
    "pred_sample[\"TARGET\"] = pred_target\n",
    "\n",
    "pred_sample.to_csv(\"./result/submission-025-keras01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = np.zeros(train_app.shape[0])\n",
    "\n",
    "for i in range(5):\n",
    "    valid_idx_fn = \"./neptune-features/valid_idx_{}.npy\".format(i)\n",
    "    valid_idx = np.load(valid_idx_fn)\n",
    "    oof_pred[valid_idx] = pred_valid_stack[i].reshape(len(valid_idx))\n",
    "    \n",
    "oof_df = train_app[[\"SK_ID_CURR\"]].copy()\n",
    "oof_df[\"SK_ID_CURR\"] = oof_df.SK_ID_CURR.astype(\"int\")\n",
    "oof_df[\"oof_pred\"] = oof_pred\n",
    "oof_df.to_csv(\"./oof-result/oof-024-keras01.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
