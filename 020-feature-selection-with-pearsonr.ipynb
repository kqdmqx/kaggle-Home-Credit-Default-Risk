{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(path, dataframe):\n",
    "    np.save(path + \".data\", dataframe.values)\n",
    "    np.save(path + \".header\", dataframe.columns)\n",
    "    \n",
    "def load_dataframe(path):\n",
    "    data = np.load(path + \".data.npy\")\n",
    "    header = np.load(path + \".header.npy\")\n",
    "    return pd.DataFrame(data=data, columns=header)\n",
    "\n",
    "def save_dataframe32(path, dataframe, keep=[]):\n",
    "    col64 = [col_ for col_ in dataframe.columns if col_ in keep]\n",
    "    col32 = [col_ for col_ in dataframe.columns if col_ not in keep]\n",
    "    dataframe64 = dataframe[col64]\n",
    "    dataframe32 = dataframe[col32]\n",
    "    np.save(path + \".data64\", dataframe64.values)\n",
    "    np.save(path + \".header64\", col64)\n",
    "    np.save(path + \".data32\", dataframe32.values.astype(np.float32))\n",
    "    np.save(path + \".header32\", col32)\n",
    "\n",
    "def load_dataframe32(path):\n",
    "    path_data32 = path + \".data32.npy\"\n",
    "    path_header32 = path + \".header32.npy\"\n",
    "    path_data64 = path + \".data64.npy\"\n",
    "    path_header64 = path + \".header64.npy\"\n",
    "    result = pd.DataFrame()\n",
    "    if os.path.exists(path_data32):\n",
    "        data32 = np.load(path_data32)\n",
    "        header32 = np.load(path_header32)\n",
    "        df32 = pd.DataFrame(data=data32, columns=header32)\n",
    "        result = pd.concat([result, df32], axis=1)\n",
    "    if os.path.exists(path_data64):\n",
    "        data64 = np.load(path_data64)\n",
    "        header64 = np.load(path_header64)\n",
    "        df64 = pd.DataFrame(data=data64, columns=header64)\n",
    "        result = pd.concat([result, df64], axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "class CatboostWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "        \n",
    "class LightGBMWrapper:\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['feature_fraction_seed'] = seed\n",
    "        params['bagging_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try scipy.stats.pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9626907, 8.103413702351178e-06)\n",
      "(-1.0, 0.0)\n",
      "(1.0, 0.0)\n",
      "(nan, 1.0)\n",
      "(nan, 1.0)\n",
      "(nan, 1.0)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10).astype(np.float32)\n",
    "\n",
    "print(pearsonr(x, x ** 2))\n",
    "print(pearsonr(x, -x))\n",
    "print(pearsonr(x, 2 * x))\n",
    "\n",
    "x[0] = np.NaN\n",
    "\n",
    "print(pearsonr(x, x ** 2))\n",
    "print(pearsonr(x, -x))\n",
    "print(pearsonr(x, 2 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626907\n",
      "1.0\n",
      "1.0\n",
      "0.9626907\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def corr(x, y):\n",
    "    x, y = x.copy(), y.copy()\n",
    "    x[np.isnan(x)] = 0.0\n",
    "    y[np.isnan(y)] = 0.0\n",
    "    return np.abs(pearsonr(x, y)[0])\n",
    "\n",
    "x = np.arange(10).astype(np.float32)\n",
    "\n",
    "print(corr(x, x ** 2))\n",
    "print(corr(x, -x))\n",
    "print(corr(x, 2 * x))\n",
    "\n",
    "x[0] = np.NaN\n",
    "\n",
    "print(corr(x, x ** 2))\n",
    "print(corr(x, -x))\n",
    "print(corr(x, 2 * x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe32(\"./bindata/data_013\")\n",
    "data[\"SK_ID_CURR\"] = data.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "test = load_dataframe32(\"./bindata/test_013\")\n",
    "test[\"SK_ID_CURR\"] = test.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "y = load_dataframe32(\"./bindata/y_013\")\n",
    "y[\"SK_ID_CURR\"] = y.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "features_selected = list(np.load(\"./models/features-selected-016.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_name in (\n",
    "    \"buro_wide_013\",\n",
    "    \"buro_full_wide_013\",\n",
    "    \"pos_bal_wide_013\",\n",
    "    \"cc_bal_wide_013\",\n",
    "    \"buro_bal_timestep1_013\",\n",
    "    \"buro_bal_timestep2_013\",\n",
    "    \"pos_bal_timestep1_013\",\n",
    "    \"pos_bal_timestep2_013\",\n",
    "    \"cc_bal_timestep1_013\",\n",
    "    \"cc_bal_timestep2_013\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name + \"_nmf5\"\n",
    "    nmf_data = load_dataframe32(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data = data.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    test = test.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del nmf_data\n",
    "    gc.collect()\n",
    "    \n",
    "buro_wide = load_dataframe32(\"./bindata/buro_wide_013\")\n",
    "buro_full_wide = load_dataframe32(\"./bindata/buro_full_wide_013\")\n",
    "pos_bal_wide = load_dataframe32(\"./bindata/pos_bal_wide_013\")\n",
    "cc_bal_wide = load_dataframe32(\"./bindata/cc_bal_wide_013\")\n",
    "\n",
    "buro_wide[\"SK_ID_CURR\"] = buro_wide.SK_ID_CURR.astype(\"int\")\n",
    "buro_full_wide[\"SK_ID_CURR\"] = buro_full_wide.SK_ID_CURR.astype(\"int\")\n",
    "pos_bal_wide[\"SK_ID_CURR\"] = pos_bal_wide.SK_ID_CURR.astype(\"int\")\n",
    "cc_bal_wide[\"SK_ID_CURR\"] = cc_bal_wide.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "for wi, data_ in enumerate((buro_wide, buro_full_wide, pos_bal_wide, cc_bal_wide)):\n",
    "    # data_.columns = [\"w{}_{}\".format(wi, col_) for col_ in data_.columns]\n",
    "    data = data.merge(right=data_, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    test = test.merge(right=data_, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del data_\n",
    "    gc.collect()\n",
    "    \n",
    "for name in (\n",
    "    \"./bindata/bureau_and_balance_015\",\n",
    "    \"./bindata/previous_applications_015\",\n",
    "    \"./bindata/pos_cash_015\",\n",
    "    \"./bindata/installments_payments_015\",\n",
    "    \"./bindata/credit_card_balance_015\",\n",
    "):\n",
    "    data_ = load_dataframe32(name)\n",
    "    data_[\"SK_ID_CURR\"] = data_.SK_ID_CURR.astype(\"int\")\n",
    "    data = data.merge(right=data_, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    test = test.merge(right=data_, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del data_\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features_selected].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, (307507, 1250))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(X), X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_corr(X, th):\n",
    "    keep = [0]\n",
    "    remove_map = {0: []}\n",
    "    corr_mat = {}\n",
    "    for i, ftr_ in enumerate(features_selected):\n",
    "        if i in keep:\n",
    "            continue\n",
    "\n",
    "        keep_flag = True\n",
    "        for j in keep:\n",
    "            corr_ij = corr(X[:, i], X[:, j])\n",
    "            corr_mat[(i, j)] = corr_ij\n",
    "\n",
    "            if corr_ij > th:\n",
    "                keep_flag = False\n",
    "                remove_map[j].append(i)\n",
    "                break\n",
    "\n",
    "        if keep_flag:\n",
    "            keep.append(i)\n",
    "            remove_map[i] = []\n",
    "    return keep, remove_map, corr_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do selection on data[features_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep, remove_map, corr_mat = select_by_corr(X, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(corr_mat.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(v == 1 for v in corr_mat.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected_20 = np.array(features_selected)[keep]\n",
    "np.save(\"./models/features-selected-020\", features_selected_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [key[0] for key, val in corr_mat.items() if val == 1.0]\n",
    "\n",
    "features_selected_20_less = [col_ for i, col_ in enumerate(features_selected) if i not in dup]\n",
    "np.save(\"./models/features-selected-0201\", features_selected_20_less)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_val = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "\n",
    "ydata_train = y[y.SK_ID_CURR < 130000]\n",
    "ydata_val = y[(y.SK_ID_CURR >= 130000) & (y.SK_ID_CURR < 150000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25803, 2030)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7676246095871037"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_train = data_train[features_selected_20].values\n",
    "X_num_val = data_val[features_selected_20].values\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "lgb_params =  {\n",
    "    \"nthread\": 8,\n",
    "    \"n_estimators\": 250, # 10000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 34,\n",
    "    \"colsample_bytree\": 0.9497036,\n",
    "    \"subsample\": 0.8715623,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_alpha\": 0.041545473,\n",
    "    \"reg_lambda\": 0.0735294,\n",
    "    \"min_split_gain\": 0.0222415,\n",
    "    \"min_child_weight\": 39.3259775,\n",
    "    \"random_state\": 0,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "lg_clf = LightGBMWrapper(clf=LGBMClassifier, seed=0, params=lgb_params)\n",
    "lg_clf.train(X_num_train, y_train)\n",
    "pred_val = lg_clf.predict(X_num_val)\n",
    "roc_auc_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7680950455454033"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup = [key[0] for key, val in corr_mat.items() if val == 1.0]\n",
    "features_selected_20_less = [col_ for i, col_ in enumerate(features_selected) if i not in dup]\n",
    "\n",
    "X_num_train = data_train[features_selected_20_less].values\n",
    "X_num_val = data_val[features_selected_20_less].values\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "lgb_params =  {\n",
    "    \"nthread\": 8,\n",
    "    \"n_estimators\": 250, # 10000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 34,\n",
    "    \"colsample_bytree\": 0.9497036,\n",
    "    \"subsample\": 0.8715623,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_alpha\": 0.041545473,\n",
    "    \"reg_lambda\": 0.0735294,\n",
    "    \"min_split_gain\": 0.0222415,\n",
    "    \"min_child_weight\": 39.3259775,\n",
    "    \"random_state\": 0,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "lg_clf = LightGBMWrapper(clf=LGBMClassifier, seed=0, params=lgb_params)\n",
    "lg_clf.train(X_num_train, y_train)\n",
    "pred_val = lg_clf.predict(X_num_val)\n",
    "roc_auc_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0\n",
      "(307507, 775) (48744, 775)\n",
      "0.016750959555308025\n",
      "15.479918734232585\n",
      "0.07988790671030681\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "\n",
    "features_selected_20 = list(np.load(\"./models/features-selected-020.npy\"))\n",
    "seed = 0\n",
    "\n",
    "\n",
    "X_data = data[features_selected_20].values\n",
    "X_test = test[features_selected_20].values\n",
    "gc.collect()\n",
    "\n",
    "print(\"seed\", seed)\n",
    "print(X_data.shape, X_test.shape)\n",
    "\n",
    "y_data = y.TARGET.values\n",
    "\n",
    "\n",
    "lgb_params =  {\n",
    "    \"nthread\": 8,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 34,\n",
    "    \"colsample_bytree\": 0.9497036,\n",
    "    \"subsample\": 0.8715623,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_alpha\": 0.041545473,\n",
    "    \"reg_lambda\": 0.0735294,\n",
    "    \"min_split_gain\": 0.0222415,\n",
    "    \"min_child_weight\": 39.3259775,\n",
    "    \"random_state\": 0,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print((b - a) / 60)\n",
    "\n",
    "lg_clf = LightGBMWrapper(clf=LGBMClassifier, seed=0, params=lgb_params)\n",
    "lg_clf.train(X_data, y_data)\n",
    "\n",
    "c = time.time()\n",
    "print((time.time() - b) / 60)\n",
    "\n",
    "pred_test = lg_clf.predict(X_test)\n",
    "print((time.time() - c) / 60)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"./models/lgb-020-nround2000-fs20-rd{}\".format(seed), \"wb\") as ofile:\n",
    "    pickle.dump(lg_clf, ofile, 0)\n",
    "\n",
    "np.save(\"./result/submission-020-lgb2000-fs20-rd{}\".format(seed), pred_test)\n",
    "\n",
    "test[\"TARGET\"] = pred_test\n",
    "test[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(\"./result/submission-020-lgb2000-fs20-rd{}.csv\".format(seed), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0\n",
      "(307507, 1150) (48744, 1150)\n",
      "0.02630150318145752\n",
      "25.026764782269797\n",
      "0.11103968620300293\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "\n",
    "dup = [key[0] for key, val in corr_mat.items() if val == 1.0]\n",
    "features_selected_20_less = [col_ for i, col_ in enumerate(features_selected) if i not in dup]\n",
    "seed = 0\n",
    "\n",
    "X_data = data[features_selected_20_less].values\n",
    "X_test = test[features_selected_20_less].values\n",
    "gc.collect()\n",
    "\n",
    "print(\"seed\", seed)\n",
    "print(X_data.shape, X_test.shape)\n",
    "\n",
    "y_data = y.TARGET.values\n",
    "\n",
    "\n",
    "lgb_params =  {\n",
    "    \"nthread\": 8,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 34,\n",
    "    \"colsample_bytree\": 0.9497036,\n",
    "    \"subsample\": 0.8715623,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_alpha\": 0.041545473,\n",
    "    \"reg_lambda\": 0.0735294,\n",
    "    \"min_split_gain\": 0.0222415,\n",
    "    \"min_child_weight\": 39.3259775,\n",
    "    \"random_state\": 0,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print((b - a) / 60)\n",
    "\n",
    "lg_clf = LightGBMWrapper(clf=LGBMClassifier, seed=0, params=lgb_params)\n",
    "lg_clf.train(X_data, y_data)\n",
    "\n",
    "c = time.time()\n",
    "print((time.time() - b) / 60)\n",
    "\n",
    "pred_test = lg_clf.predict(X_test)\n",
    "print((time.time() - c) / 60)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"./models/lgb-020-nround2000-fs201-rd{}\".format(seed), \"wb\") as ofile:\n",
    "    pickle.dump(lg_clf, ofile, 0)\n",
    "\n",
    "np.save(\"./result/submission-020-lgb2000-fs201-rd{}\".format(seed), pred_test)\n",
    "\n",
    "test[\"TARGET\"] = pred_test\n",
    "test[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(\"./result/submission-020-lgb2000-fs201-rd{}.csv\".format(seed), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayesian optimization --subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(data=X_num_train, label=y_train)\n",
    "n_folds = 2\n",
    "random_seed = 0\n",
    "\n",
    "def target_function(num_leaves,\n",
    "                    colsample_bytree,\n",
    "                    subsample,\n",
    "                    subsample_freq,\n",
    "                    max_depth,\n",
    "                    reg_alpha,\n",
    "                    reg_lambda,\n",
    "                    min_split_gain,\n",
    "                    min_child_weight):\n",
    "    global train_data, nfolds, random_seed\n",
    "    params = {\n",
    "        \"nthread\": 8,\n",
    "        \"n_estimators\": 250, # 2000,\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"random_state\": 0,\n",
    "        'metric':'auc',\n",
    "        \"silent\": -1,\n",
    "        \"verbose\": -1,\n",
    "        # \"num_leaves\": 34,\n",
    "        # \"colsample_bytree\": 0.9497036,\n",
    "        # \"subsample\": 0.8715623,\n",
    "        # \"subsample_freq\": 1,\n",
    "        # \"max_depth\": 8,\n",
    "        # \"reg_alpha\": 0.041545473,\n",
    "        # \"reg_lambda\": 0.0735294,\n",
    "        # \"min_split_gain\": 0.0222415,\n",
    "        # \"min_child_weight\": 39.3259775,\n",
    "    }\n",
    "    params[\"num_leaves\"] = int(round(num_leaves))\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0.1)\n",
    "    params['subsample'] = max(min(subsample, 1), 0.1)\n",
    "    params['subsample_freq'] = int(round(subsample_freq))\n",
    "    params['max_depth'] = int(round(max_depth))\n",
    "    params['reg_alpha'] = max(reg_alpha, 0)\n",
    "    params['reg_lambda'] = max(reg_lambda, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =50, metrics=['auc'])\n",
    "    return max(cv_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(\n",
    "    target_function,\n",
    "    {\n",
    "        \"num_leaves\": (30, 45),\n",
    "        \"colsample_bytree\": (.7, .99),\n",
    "        \"subsample\": (.7, .99),\n",
    "        \"subsample_freq\": (1, 5),\n",
    "        \"max_depth\": (6, 10),\n",
    "        \"reg_alpha\": (.0, .1),\n",
    "        \"reg_lambda\": (.0, .1),\n",
    "        \"min_split_gain\": (.0, .1),\n",
    "        \"min_child_weight\": (30, 45),\n",
    "    },\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_depth |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample |   subsample_freq | \n",
      "[50]\tcv_agg's auc: 0.737465 + 0.00471036\n",
      "[100]\tcv_agg's auc: 0.741807 + 0.00502509\n",
      "[150]\tcv_agg's auc: 0.745825 + 0.00457703\n",
      "[200]\tcv_agg's auc: 0.747252 + 0.00340129\n",
      "[250]\tcv_agg's auc: 0.746426 + 0.00357624\n",
      "    1 | 00m51s | \u001b[35m   0.74758\u001b[0m | \u001b[32m            0.9296\u001b[0m | \u001b[32m     7.4380\u001b[0m | \u001b[32m           34.7697\u001b[0m | \u001b[32m          0.0976\u001b[0m | \u001b[32m     38.2322\u001b[0m | \u001b[32m     0.0570\u001b[0m | \u001b[32m      0.0159\u001b[0m | \u001b[32m     0.9838\u001b[0m | \u001b[32m          2.0582\u001b[0m | \n",
      "[50]\tcv_agg's auc: 0.737889 + 0.00804477\n",
      "[100]\tcv_agg's auc: 0.742806 + 0.00890373\n",
      "[150]\tcv_agg's auc: 0.747109 + 0.00750601\n",
      "[200]\tcv_agg's auc: 0.748414 + 0.00677344\n",
      "[250]\tcv_agg's auc: 0.746824 + 0.00538624\n",
      "    2 | 01m00s | \u001b[35m   0.74863\u001b[0m | \u001b[32m            0.8534\u001b[0m | \u001b[32m     7.7481\u001b[0m | \u001b[32m           36.2139\u001b[0m | \u001b[32m          0.0469\u001b[0m | \u001b[32m     40.7278\u001b[0m | \u001b[32m     0.0439\u001b[0m | \u001b[32m      0.0110\u001b[0m | \u001b[32m     0.9318\u001b[0m | \u001b[32m          4.0969\u001b[0m | \n",
      "[50]\tcv_agg's auc: 0.737017 + 0.00710263\n",
      "[100]\tcv_agg's auc: 0.744228 + 0.00572318\n",
      "[150]\tcv_agg's auc: 0.746391 + 0.00593095\n",
      "[200]\tcv_agg's auc: 0.747996 + 0.00546863\n",
      "[250]\tcv_agg's auc: 0.747496 + 0.00590015\n",
      "    3 | 00m40s |    0.74829 |             0.8647 |      8.7905 |            30.9622 |           0.0977 |      39.0415 |      0.0988 |       0.0656 |      0.8338 |           2.8246 | \n",
      "[50]\tcv_agg's auc: 0.733096 + 0.00768602\n",
      "[100]\tcv_agg's auc: 0.740742 + 0.0075683\n",
      "[150]\tcv_agg's auc: 0.745306 + 0.00662337\n",
      "[200]\tcv_agg's auc: 0.74582 + 0.00747098\n",
      "[250]\tcv_agg's auc: 0.746529 + 0.0076867\n",
      "    4 | 00m38s |    0.74653 |             0.9684 |      6.2409 |            40.3871 |           0.0605 |      38.1732 |      0.0102 |       0.0138 |      0.9264 |           3.2737 | \n",
      "[50]\tcv_agg's auc: 0.740466 + 0.00836015\n",
      "[100]\tcv_agg's auc: 0.744324 + 0.00643337\n",
      "[150]\tcv_agg's auc: 0.747544 + 0.00561261\n",
      "[200]\tcv_agg's auc: 0.747498 + 0.00540987\n",
      "[250]\tcv_agg's auc: 0.747609 + 0.0034706\n",
      "    5 | 00m37s |    0.74800 |             0.7206 |      8.6671 |            38.4990 |           0.0739 |      36.3548 |      0.0209 |       0.0197 |      0.7343 |           1.0752 | \n",
      "[50]\tcv_agg's auc: 0.741461 + 0.00600387\n",
      "[100]\tcv_agg's auc: 0.745643 + 0.00591338\n",
      "[150]\tcv_agg's auc: 0.74757 + 0.00679592\n",
      "[200]\tcv_agg's auc: 0.747936 + 0.00589416\n",
      "[250]\tcv_agg's auc: 0.746913 + 0.00495898\n",
      "    6 | 00m58s |    0.74843 |             0.7253 |      8.6826 |            33.9808 |           0.0039 |      39.6884 |      0.0161 |       0.0369 |      0.8856 |           3.4705 | \n",
      "[50]\tcv_agg's auc: 0.74058 + 0.00644528\n",
      "[100]\tcv_agg's auc: 0.744448 + 0.00663967\n",
      "[150]\tcv_agg's auc: 0.745814 + 0.00736567\n",
      "[200]\tcv_agg's auc: 0.745184 + 0.00678074\n",
      "[250]\tcv_agg's auc: 0.745746 + 0.00423895\n",
      "    7 | 00m45s |    0.74625 |             0.7059 |      6.8415 |            37.8487 |           0.0283 |      36.5638 |      0.0653 |       0.0821 |      0.7416 |           3.4484 | \n",
      "[50]\tcv_agg's auc: 0.735075 + 0.00644024\n",
      "[100]\tcv_agg's auc: 0.740859 + 0.00693815\n",
      "[150]\tcv_agg's auc: 0.744296 + 0.00591272\n",
      "[200]\tcv_agg's auc: 0.744904 + 0.00611261\n",
      "[250]\tcv_agg's auc: 0.744516 + 0.00605166\n",
      "    8 | 00m58s |    0.74559 |             0.9415 |      6.5157 |            31.4091 |           0.0120 |      43.3766 |      0.0253 |       0.0097 |      0.9740 |           3.4677 | \n",
      "[50]\tcv_agg's auc: 0.736107 + 0.00521746\n",
      "[100]\tcv_agg's auc: 0.740742 + 0.00487411\n",
      "[150]\tcv_agg's auc: 0.744171 + 0.00524705\n",
      "[200]\tcv_agg's auc: 0.744345 + 0.0041278\n",
      "[250]\tcv_agg's auc: 0.744174 + 0.00404477\n",
      "    9 | 01m06s |    0.74491 |             0.9257 |      7.2617 |            38.6392 |           0.0296 |      44.4549 |      0.0466 |       0.0838 |      0.8513 |           4.7750 | \n",
      "[50]\tcv_agg's auc: 0.739409 + 0.00933097\n",
      "[100]\tcv_agg's auc: 0.74315 + 0.00768466\n",
      "[150]\tcv_agg's auc: 0.74539 + 0.00594323\n",
      "[200]\tcv_agg's auc: 0.746435 + 0.0057081\n",
      "[250]\tcv_agg's auc: 0.746792 + 0.00481659\n",
      "   10 | 00m51s |    0.74740 |             0.9523 |      7.4548 |            43.9394 |           0.0119 |      35.7516 |      0.0244 |       0.0096 |      0.8203 |           3.7273 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_depth |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample |   subsample_freq | \n",
      "[50]\tcv_agg's auc: 0.733584 + 0.00735614\n",
      "[100]\tcv_agg's auc: 0.743047 + 0.00811719\n",
      "[150]\tcv_agg's auc: 0.74607 + 0.00695404\n",
      "[200]\tcv_agg's auc: 0.746972 + 0.00503507\n",
      "[250]\tcv_agg's auc: 0.746633 + 0.00472011\n",
      "   11 | 01m18s |    0.74734 |             0.9897 |      9.8981 |            37.8914 |           0.0647 |      30.2367 |      0.0643 |       0.0223 |      0.9213 |           4.9615 | \n",
      "[50]\tcv_agg's auc: 0.734201 + 0.00834459\n",
      "[100]\tcv_agg's auc: 0.743663 + 0.00450528\n",
      "[150]\tcv_agg's auc: 0.746718 + 0.0047301\n",
      "[200]\tcv_agg's auc: 0.747093 + 0.00438492\n",
      "[250]\tcv_agg's auc: 0.745038 + 0.00246558\n",
      "   12 | 01m30s |    0.74712 |             0.9708 |      9.9638 |            39.4751 |           0.0175 |      36.3763 |      0.0290 |       0.0628 |      0.7097 |           4.9498 | \n",
      "[50]\tcv_agg's auc: 0.737667 + 0.00640164\n",
      "[100]\tcv_agg's auc: 0.744566 + 0.0055225\n",
      "[150]\tcv_agg's auc: 0.748035 + 0.00525922\n",
      "[200]\tcv_agg's auc: 0.748885 + 0.00511083\n",
      "[250]\tcv_agg's auc: 0.749183 + 0.00536823\n",
      "   13 | 01m06s | \u001b[35m   0.74955\u001b[0m | \u001b[32m            0.8825\u001b[0m | \u001b[32m     6.1379\u001b[0m | \u001b[32m           44.8429\u001b[0m | \u001b[32m          0.0305\u001b[0m | \u001b[32m     30.0336\u001b[0m | \u001b[32m     0.0833\u001b[0m | \u001b[32m      0.0426\u001b[0m | \u001b[32m     0.9550\u001b[0m | \u001b[32m          1.1003\u001b[0m | \n",
      "[50]\tcv_agg's auc: 0.738666 + 0.00707773\n",
      "[100]\tcv_agg's auc: 0.74394 + 0.00781364\n",
      "[150]\tcv_agg's auc: 0.746559 + 0.00784682\n",
      "[200]\tcv_agg's auc: 0.747811 + 0.0071334\n",
      "[250]\tcv_agg's auc: 0.747792 + 0.00620554\n",
      "   14 | 01m15s |    0.74847 |             0.7355 |      9.9084 |            44.9498 |           0.0307 |      30.1849 |      0.0789 |       0.0890 |      0.9504 |           1.0529 | \n",
      "[50]\tcv_agg's auc: 0.738096 + 0.00659782\n",
      "[100]\tcv_agg's auc: 0.744238 + 0.0081326\n",
      "[150]\tcv_agg's auc: 0.748347 + 0.00781664\n",
      "[200]\tcv_agg's auc: 0.74809 + 0.00843479\n",
      "[250]\tcv_agg's auc: 0.746969 + 0.00799976\n",
      "   15 | 01m14s |    0.74871 |             0.7552 |      9.9729 |            31.3503 |           0.0749 |      44.7259 |      0.0834 |       0.0245 |      0.9048 |           1.7708 | \n",
      "[50]\tcv_agg's auc: 0.740974 + 0.00413552\n",
      "[100]\tcv_agg's auc: 0.744047 + 0.00452967\n",
      "[150]\tcv_agg's auc: 0.748919 + 0.00504702\n",
      "[200]\tcv_agg's auc: 0.750114 + 0.00539709\n",
      "[250]\tcv_agg's auc: 0.750337 + 0.00540751\n",
      "   16 | 00m59s | \u001b[35m   0.75063\u001b[0m | \u001b[32m            0.7188\u001b[0m | \u001b[32m     6.0130\u001b[0m | \u001b[32m           30.0176\u001b[0m | \u001b[32m          0.0672\u001b[0m | \u001b[32m     30.1655\u001b[0m | \u001b[32m     0.0569\u001b[0m | \u001b[32m      0.0371\u001b[0m | \u001b[32m     0.8590\u001b[0m | \u001b[32m          4.9576\u001b[0m | \n",
      "[50]\tcv_agg's auc: 0.74211 + 0.00912311\n",
      "[100]\tcv_agg's auc: 0.74793 + 0.00722018\n",
      "[150]\tcv_agg's auc: 0.748711 + 0.00778162\n",
      "[200]\tcv_agg's auc: 0.747545 + 0.00644188\n",
      "[250]\tcv_agg's auc: 0.747431 + 0.00603526\n",
      "   17 | 01m39s |    0.74914 |             0.9132 |      9.8936 |            44.8655 |           0.0099 |      44.8531 |      0.0516 |       0.0141 |      0.8497 |           1.1929 | \n",
      "[50]\tcv_agg's auc: 0.739159 + 0.00514886\n",
      "[100]\tcv_agg's auc: 0.744261 + 0.00586981\n",
      "[150]\tcv_agg's auc: 0.747042 + 0.00482076\n",
      "[200]\tcv_agg's auc: 0.748709 + 0.00532686\n",
      "[250]\tcv_agg's auc: 0.747334 + 0.00381099\n",
      "   18 | 01m14s |    0.74904 |             0.7482 |      9.9423 |            30.4585 |           0.0951 |      44.8813 |      0.0441 |       0.0012 |      0.9544 |           4.9993 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's auc: 0.736052 + 0.00472278\n",
      "[100]\tcv_agg's auc: 0.742259 + 0.00649679\n",
      "[150]\tcv_agg's auc: 0.747723 + 0.00509546\n",
      "[200]\tcv_agg's auc: 0.749084 + 0.004445\n",
      "[250]\tcv_agg's auc: 0.748469 + 0.00380065\n",
      "   19 | 01m17s |    0.74997 |             0.7954 |      9.9797 |            30.0023 |           0.0923 |      30.9836 |      0.0652 |       0.0308 |      0.9167 |           4.5956 | \n",
      "[50]\tcv_agg's auc: 0.738202 + 0.00904526\n",
      "[100]\tcv_agg's auc: 0.745058 + 0.00679577\n",
      "[150]\tcv_agg's auc: 0.745904 + 0.00481763\n",
      "[200]\tcv_agg's auc: 0.746007 + 0.00476226\n",
      "[250]\tcv_agg's auc: 0.74627 + 0.00439097\n",
      "   20 | 01m25s |    0.74670 |             0.9275 |      9.9768 |            44.1335 |           0.0663 |      39.5412 |      0.0996 |       0.0193 |      0.9444 |           1.0257 | \n",
      "[50]\tcv_agg's auc: 0.738858 + 0.00798491\n",
      "[100]\tcv_agg's auc: 0.745681 + 0.00678437\n",
      "[150]\tcv_agg's auc: 0.749785 + 0.00605856\n",
      "[200]\tcv_agg's auc: 0.752286 + 0.00561546\n",
      "[250]\tcv_agg's auc: 0.751769 + 0.00361549\n",
      "   21 | 01m01s | \u001b[35m   0.75269\u001b[0m | \u001b[32m            0.7508\u001b[0m | \u001b[32m     9.8763\u001b[0m | \u001b[32m           30.4956\u001b[0m | \u001b[32m          0.0916\u001b[0m | \u001b[32m     30.1288\u001b[0m | \u001b[32m     0.0927\u001b[0m | \u001b[32m      0.0052\u001b[0m | \u001b[32m     0.7027\u001b[0m | \u001b[32m          1.1354\u001b[0m | \n",
      "[50]\tcv_agg's auc: 0.739747 + 0.00742778\n",
      "[100]\tcv_agg's auc: 0.746011 + 0.00580711\n",
      "[150]\tcv_agg's auc: 0.749626 + 0.00616125\n",
      "[200]\tcv_agg's auc: 0.750318 + 0.00469867\n",
      "[250]\tcv_agg's auc: 0.749872 + 0.00387109\n",
      "   22 | 00m55s |    0.75047 |             0.7040 |      6.0902 |            44.1495 |           0.0949 |      30.5139 |      0.0328 |       0.0161 |      0.7467 |           4.7299 | \n",
      "[50]\tcv_agg's auc: 0.740549 + 0.00643449\n",
      "[100]\tcv_agg's auc: 0.744558 + 0.00407054\n",
      "[150]\tcv_agg's auc: 0.748055 + 0.00374111\n",
      "[200]\tcv_agg's auc: 0.748986 + 0.00416932\n",
      "[250]\tcv_agg's auc: 0.749171 + 0.00280022\n",
      "   23 | 01m06s |    0.74918 |             0.9422 |      6.9970 |            30.1044 |           0.0955 |      30.6331 |      0.0021 |       0.0055 |      0.7604 |           1.2759 | \n",
      "[50]\tcv_agg's auc: 0.743839 + 0.00844773\n",
      "[100]\tcv_agg's auc: 0.746551 + 0.00744044\n",
      "[150]\tcv_agg's auc: 0.74656 + 0.0073434\n",
      "[200]\tcv_agg's auc: 0.74567 + 0.00618921\n",
      "[250]\tcv_agg's auc: 0.745227 + 0.00590805\n",
      "   24 | 01m14s |    0.74754 |             0.7252 |      9.8116 |            44.6956 |           0.0989 |      44.4079 |      0.0301 |       0.0164 |      0.7835 |           4.9386 | \n",
      "[50]\tcv_agg's auc: 0.736248 + 0.00742044\n",
      "[100]\tcv_agg's auc: 0.742907 + 0.00477184\n",
      "[150]\tcv_agg's auc: 0.745532 + 0.00531149\n",
      "[200]\tcv_agg's auc: 0.747241 + 0.00528568\n",
      "[250]\tcv_agg's auc: 0.74701 + 0.00541146\n",
      "   25 | 01m07s |    0.74797 |             0.9836 |      6.1713 |            36.3978 |           0.0504 |      30.0009 |      0.0561 |       0.0063 |      0.7089 |           4.9799 | \n",
      "[50]\tcv_agg's auc: 0.737323 + 0.00519801\n",
      "[100]\tcv_agg's auc: 0.742911 + 0.00434977\n",
      "[150]\tcv_agg's auc: 0.746279 + 0.00445353\n",
      "[200]\tcv_agg's auc: 0.748403 + 0.00391889\n",
      "[250]\tcv_agg's auc: 0.747637 + 0.00234872\n",
      "   26 | 01m11s |    0.74900 |             0.7394 |      9.9985 |            30.3375 |           0.0753 |      32.8162 |      0.0954 |       0.0028 |      0.9706 |           1.4239 | \n",
      "[50]\tcv_agg's auc: 0.739648 + 0.00622676\n",
      "[100]\tcv_agg's auc: 0.745608 + 0.00557936\n",
      "[150]\tcv_agg's auc: 0.748529 + 0.00451348\n",
      "[200]\tcv_agg's auc: 0.748707 + 0.00432374\n",
      "[250]\tcv_agg's auc: 0.749141 + 0.00347448\n",
      "   27 | 01m05s |    0.74923 |             0.7055 |      6.4707 |            44.8447 |           0.0621 |      44.8915 |      0.0852 |       0.0136 |      0.7605 |           1.3288 | \n",
      "[50]\tcv_agg's auc: 0.740834 + 0.00710712\n",
      "[100]\tcv_agg's auc: 0.745611 + 0.00773202\n",
      "[150]\tcv_agg's auc: 0.746846 + 0.00594162\n",
      "[200]\tcv_agg's auc: 0.746836 + 0.00577018\n",
      "[250]\tcv_agg's auc: 0.747894 + 0.00401909\n",
      "   28 | 01m04s |    0.74800 |             0.7860 |      9.0988 |            44.8702 |           0.0788 |      30.3217 |      0.0793 |       0.0086 |      0.7048 |           3.9879 | \n",
      "[50]\tcv_agg's auc: 0.739432 + 0.008116\n",
      "[100]\tcv_agg's auc: 0.744918 + 0.00504626\n",
      "[150]\tcv_agg's auc: 0.747232 + 0.00372997\n",
      "[200]\tcv_agg's auc: 0.748228 + 0.00294825\n",
      "[250]\tcv_agg's auc: 0.746507 + 0.00207527\n",
      "   29 | 01m09s |    0.74839 |             0.9620 |      9.7836 |            33.2583 |           0.0968 |      30.0141 |      0.0793 |       0.0632 |      0.7573 |           1.2716 | \n",
      "[50]\tcv_agg's auc: 0.739989 + 0.00790552\n",
      "[100]\tcv_agg's auc: 0.746062 + 0.00660384\n",
      "[150]\tcv_agg's auc: 0.748534 + 0.00525836\n",
      "[200]\tcv_agg's auc: 0.748454 + 0.00496433\n",
      "[250]\tcv_agg's auc: 0.747776 + 0.0043759\n",
      "   30 | 01m04s |    0.74894 |             0.7432 |      9.8329 |            33.0180 |           0.0999 |      41.6338 |      0.0235 |       0.0064 |      0.7088 |           1.0400 | \n"
     ]
    }
   ],
   "source": [
    "lgbBO.maximize(init_points=10, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFNCAYAAAAtqDcVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl81Nd56P/PdzaNpNGu0QISQpIldgwyYBsbO3FCnGZz\nndoG2pq29k1vbtukCfQVx81GDQbcm8TtTXLJz71dUuwkJI4bQ5PYCV6CjbGxAQECIbFoRdugdUYz\nmvX7+0Oakdg0I2l2Pe/XK69YaDRzDkJ65pzznOdRVFVVEUIIIUTc08R6AEIIIYQIjQRtIYQQIkFI\n0BZCCCEShARtIYQQIkFI0BZCCCEShARtIYQQIkHogj3A5/Oxbds2GhoaMBgM7Nixg7KyMgAsFgtb\ntmwJPLa+vp6tW7eyadMmHnzwQUwmEwAlJSXs2rWLCxcu8I1vfANVVZk/fz47duxApws6BCGEEEIQ\nQtA+ePAgLpeLffv2UVtby+7du9mzZw8AZrOZvXv3AnDixAmeffZZHnnkEZxOJ6qqBj7n993vfpct\nW7awevVqvvrVr/LGG2+wfv36CExLCCGESD5Bg/axY8dYt24dACtWrKCuru66x6iqyvbt2/n2t7+N\nVqulrq4Oh8PBY489hsfjYcuWLaxYsYLvfe97aLVaXC4XFoslsBIXQgghRHBBg7bNZrsquGq1Wjwe\nz1Xb2q+//jpVVVVUVFQAYDQaefzxx3n44Ydpbm7mc5/7HK+88go6nY7Lly/zF3/xF5hMJhYuXBiB\nKQkhhBDJKWjQNplMDA8PBz72+XzXnUPv37+fzZs3Bz4uLy+nrKwMRVEoLy8nOzsbi8VCcXExc+fO\n5be//S0///nP2b17N88888xNX9tisU5nTpPKyUmjv98e9ueNpWScEyTnvGROiSMZ55WMc4Lkm5fZ\nnHHTzwXNHq+pqeHQoUMA1NbWUl1dfd1j6urqqKmpCXz84osvsnv3bgC6u7ux2WyYzWY+//nP09zc\nDEB6ejoaTfST13U6bdRfM9KScU6QnPOSOSWOZJxXMs4JkndeNxJ0pb1+/XoOHz7Mxo0bUVWVnTt3\ncuDAAex2Oxs2bKCvrw+TyYSiKIGveeihh3jyySfZtGkTiqKwc+dOdDodf/mXf8lXv/pV9Ho9qamp\n7NixI6KTE0IIIZKJEs9dviKxPW42Z0TkeWMpGecEyTkvmVPiSMZ5JeOcIPnmNaPtcSGEEELEBwna\nQgghRIKQoC2EEEIkCAnaQgghRIKQoC2EEEIkCAnaQgghRIKQoC2EEEIkCAnaQgghRIKQoC2EmDar\n3cWR0x2xHoYQs4YEbSHEtL16tI2d//E+F9oHYz0UIWYFCdpCiGnrt44AcOGyBG0hokGCthBi2qwO\nNwCXOodiPBIhZgcJ2kKIabPZR4N2U4cEbSGiQYK2EGLabGMr7d6hEQaHXTEejRDJT4K2EGLa/Nvj\nIKttIaJBgrYQYlrcHi9Olxe9bvTXiJxrCxF5ErSFENNiHTvPXlaZD0CTBG0hIk6CthBiWvzn2XPM\n6RTkpNLUMYSqqjEelRDJTYK2EGJa/OfZWaYUKoozsTs9dPc7YjwqIZKbBG0hxLT4r3tlphson5MJ\nSDKaEJEmQVsIMS3+7fHMdAMVxaNBW5LRhIgsXawHIIRITFb76L3szHQD+el6tBpFktGEiDBZaQsh\npmV8pZ2CXqelpMBEa7cVt8cX45EJkbwkaAshpmXi9jhAxZxMPF6VdostlsMSIqlJ0BZCTIv/nnZG\n2ljQ9p9rSzKaEBEjQVsIMS1Wu5vUFG2gIlr5WNCWc20hIkeCthBiWmwOF6ZUfeDjorw0UlO0stIW\nIoIkaAshpkxVVWwOd2BrHECjKMwvyqSrz459xD3JVwshpkuCthBiykZcXjxe9aqVNowmowE0dVlj\nMSwhkp4EbSHElPkzxzOuCdqBc23ZIhciIiRoCyGmzB+0TWk3Dtpyri1EZEjQFkJMmf+617Xb4zkZ\nKeRkpHCpUzp+CREJErSFEFNmc4yWMJ2YiOZXUZzJ0LCLfqsz2sMSIulJ0BZCTNnNVtpAoOOXbJEL\nEX4StIUQUxY4075R0JaOX0JEjARtIcSUjZcwvT5ozy/KQEEyyIWIBAnaQogpC1z5usGZdmqKjjn5\n6TR3WfH5JBlNiHCSoC2EmDKb3YWiQFqK7oafLy/OxOn20tE7HOWRCZHcbvwTN4HP52Pbtm00NDRg\nMBjYsWMHZWVlAFgsFrZs2RJ4bH19PVu3bmXTpk08+OCDmEwmAEpKSti1axf19fVs374drVaLwWDg\nmWeeIT8/P0JTE0JEitXhJt2oR6NRbvj58jmZvH26k0sdQ5SYTVEenRDJK2jQPnjwIC6Xi3379lFb\nW8vu3bvZs2cPAGazmb179wJw4sQJnn32WR555BGcTieqqgY+5/f000/zjW98g0WLFvHTn/6Uf/mX\nf+HJJ5+MwLSEEJE0Wnf8+vNsv4oJHb/uuXVOtIYlRNILuj1+7Ngx1q1bB8CKFSuoq6u77jGqqrJ9\n+3a2bduGVqvl3LlzOBwOHnvsMTZv3kxtbS0A3/3ud1m0aBEAXq+XlJSUcM5FCBEFvrFmITfKHPeb\na05Hr9NIMpoQYRZ0pW2z2QLb3ABarRaPx4NON/6lr7/+OlVVVVRUVABgNBp5/PHHefjhh2lubuZz\nn/scr7zyCgUFBQAcP36c559/nhdeeGHS187JSUOn005rYpMxmzPC/pyxloxzguScV6LPaWjYhapC\nXnZqYC43mtMtJdk0tPaTkZWK0RD0V01cSvTv1Y0k45wgeed1raA/SSaTieHh8WQSn893VcAG2L9/\nP5s3bw58XF5eTllZGYqiUF5eTnZ2NhaLheLiYn7961+zZ88ennvuOXJzcyd97f5++1TnE5TZnIHF\nklwdiJJxTpCc80qGOXWOJZcZtAoWi/WmcyrJT6e+uY9jdZ1Ul2ZHe5gzlgzfq2sl45wg+eY12RuQ\noNvjNTU1HDp0CIDa2lqqq6uve0xdXR01NTWBj1988UV2794NQHd3NzabDbPZzMsvv8zzzz/P3r17\nKS0tnfJEhBCxN15Y5frrXhMF2nRKkRUhwiboSnv9+vUcPnyYjRs3oqoqO3fu5MCBA9jtdjZs2EBf\nXx8mkwlFGc8ifeihh3jyySfZtGkTiqKwc+dOFEXh6aefpri4mC984QsArF69mi9+8YuRm50QIuxs\nkxRWmahcgrYQYRc0aGs0Gp566qmr/qyysjLw37m5ubz88stXfd5gMPCd73znuuc6evTodMcphIgT\n1klKmE5kzjJiStVLDXIhwkiKqwghpmS8GtrkQVtRFMqLM7kyOMKQ3RWNoQmR9CRoCyGmxGYP7Uwb\nJpxry2pbiLCQoC2EmBLrWC9tU5CVNox3/JJzbSHCQ4K2EGJKAoloQc60AcqLR6+uSJtOIcJDgrYQ\nYkqsDjdajYLRELzwUUaagYLsVJo6hlBV6fglxExJ0BZCTInN7saUpr/qmudkyudkMjzioWfAEeGR\nCZH8JGgLIabE6nCHtDXuFzjXlmQ0IWZMgrYQImQerw+H00NGWvDMcT9/xy851xZi5iRoCyFCNhxi\nYZWJ5hWa0GoUWWkLEQYStIUQIQtUQwvhupefQa+lxGyipduGx+uL1NCEmBUkaAshQjaV614Tlc/J\nxOP10W6xRWJYQswaErSFECGzTWN7HMbva8sWuRAzI0FbCBEyqz30amgTVczJApDmIULMkARtIUTI\n/GfaGSHUHZ+oODcNo0ErGeRCzJAEbSFEyMabhUxtpa3RKMwvyqCr1459xBOJoQkxK0jQFkKELNS2\nnDdSPicTFWjpktW2ENMlQVsIETLrNBPRACqKx861ZYtciGmToC2ECJnN7iZFr8WgD94s5Fr+3tqS\njCbE9EnQFkKEzOZwTWuVDZCTkUK2ySC9tYWYAQnaQoiQWR3uKV/3mqi8OJMBm4t+qzOMoxJi9pCg\nLYQIidPtxeX2Tbka2kTjW+SD4RqWELOKBG0hREgC171msNKWjl9CzIwEbSFESKZbwnSisqJMFKSc\nqRDTJUFbCBESq2O0hOlMtsfTjDqK8tJo7rLi86nhGpoQs4YEbSFESAIdvtKmVsL0WhVzMhlxeens\nHQ7HsISYVSRoCyFCMpPCKhPJubYQ0ydBWwgRkvGV9syCdvlYBnlTp3XGYxJitpGgLYQISTgS0QBK\nzCZ0Wo0kowkxDRK0hRAhCWyPz/BMW6fVUFZkot1iw+X2hmNoQswaErSFECGx2Uezx9ONuhk/V3lx\nJl6fSmu3bcbPJcRsIkFbCBESq8NNWooOnXbmvzYkGU2I6ZGgLYQIic0+s7rjE5VLOVMhpkWCthAi\nKFVVsTncMyqsMlFBdirpRp10/BJiiiRoCyGCcji9eH3qjAur+CmKQvmcTCwDI1jHzsqFEMFJ0BZC\nBGUbK2E60+teE/nPteW+thChk6AthAhq/LpX+IJ2ebGcawsxVRK0hRBBBaqhhXGlLZXRhJi6oBcu\nfT4f27Zto6GhAYPBwI4dOygrKwPAYrGwZcuWwGPr6+vZunUrmzZt4sEHH8RkMgFQUlLCrl27Ao/b\nuXMn5eXlbNq0KdzzEUJEQLiqoU2UmWYgP8tIU+cQqqqiKErYnluIZBU0aB88eBCXy8W+ffuora1l\n9+7d7NmzBwCz2czevXsBOHHiBM8++yyPPPIITqcTVVUDn/Pr6+vjK1/5Cs3NzTz++OMRmI4QIhKs\n9vBvj8Nox6+j9T1YBkcoyE4N63MLkYyCbo8fO3aMdevWAbBixQrq6uque4yqqmzfvp1t27ah1Wo5\nd+4cDoeDxx57jM2bN1NbWwvA8PAwX/jCF3jggQfCPA0hRCSN99IOT/a4n5xrCzE1QVfaNpstsM0N\noNVq8Xg86HTjX/r6669TVVVFRUUFAEajkccff5yHH36Y5uZmPve5z/HKK69QWlpKaWkphw4dCmlw\nOTlp6HTaqc4pKLM5I+zPGWvJOCdIznkl4pw8vtH/n1eSjdlsuu7z051TzeIi9r1+ga6Bkbj8e4nH\nMc1UMs4Jknde1woatE0mE8PD483qfT7fVQEbYP/+/WzevDnwcXl5OWVlZaN3McvLyc7OxmKxUFxc\nPKXB9ffbp/T4UJjNGVgsyZX4koxzguScV6LO6crYz6J7xHXd+Gcyp8wULRpF4ezF3rj7e0nU79Vk\nknFOkHzzmuwNSNDt8ZqamsDKuLa2lurq6useU1dXR01NTeDjF198kd27dwPQ3d2NzWbDbDZPeeBC\niPhgdbjRKAqpKTNvFjJRil5LiTmdlm4rHq8vrM8tRDIK+hO4fv16Dh8+zMaNG1FVlZ07d3LgwAHs\ndjsbNmygr68Pk8l0VebnQw89xJNPPsmmTZtQFIWdO3detzoXQiQOm92NKVWHJgIZ3uVzMmntsXHZ\nMkxZ0ezY4hRiuoJGUo1Gw1NPPXXVn1VWVgb+Ozc3l5dffvmqzxsMBr7zne/c9Dm/8IUvTHWcQogY\nsjncZKaHNwnNr6I4k9/XdnCpc0iCthBBSHEVIcSkfD6VYYc7rHe0JwoUWemQ5iFCBCNBWwgxKduI\nG5XwVkObaE5eOil6rXT8EiIEErSFEJOyRaiwip9GozC/KIOOK8M4nJ6IvIYQyUKCthBiUpEoYXqt\nijmZqEBzV/Jc2xEiEiRoCyEmZY1As5BrlQfadMoWuRCTkaAthJiUv5d2RlpkssdhdKUNkowmRDAS\ntIUQk7JFoJf2tXIyUshKN3BJVtpCTEqCthBiUoEOXxHcHlcUhYo5mfRbnfRbnRF7HSESnQRtIcSk\n/CvtSJ5pg5xrCxEKCdpCiElFY3scJhRZkaAtxE1J0BZCTMpqd6HTakjRh79N7kTlYyVML0kymhA3\nJUFbxJ12i42v7HmHs029sR6KYPRMOyNNf1VToEhIM+opzkujqXMIn6pG9LWESFQStEXcOVrfzZXB\nEX7zTnOshyIY3R6PZBLaROXFmYy4vHT12qPyekIkGgnaIu40tA4A8P7ZLumxHGNuj48RlzeqQRvk\nXFuIm5GgLeKKy+0N/MIeHvFwrrU/xiOa3QKZ4xFOQvPzF1mRc20hbkyCtogrFzuG8HjVQF/l441X\nYjyi2W38ulfkqqFNVFpgQqdVpMiKEDchQVvElYaxlfWn7iwjI83AifMWSUqKIZt9tIRppK97+em0\nGuYVZtDeY8Pt8UblNYVIJBK0RVxpbBtAARbMy2HNkkIGbS6pRx1D1ih0+LpWeXEmXp9Ka7ctaq8p\nRKKQoC3ihtvj42LHEHPNJkypeu5cWgzA8UZLjEc2ewU6fEVppQ1QUSzn2kLcjARtETeaOodwe3ws\nmJcNwIoFBaTotRxvtKDKFnlMRKOX9rWqSrIAOHVR8hmEuJYEbRE3GtpGr3otKB0N2il6LUsrcunu\nd9BxZTiWQ5u1bFFoFnKt/OxUKudmcra5X5qHCHENCdoibjSOJaFVjwVtgJoqMwDHz8uqKxasUeil\nfSNrlxajAu+e7Yrq6woR7yRoi7jg8fq4cHmI4rw0MtPHA8TyW/LQahQ5146RWGyPA6xeWIBOq/BO\nXZccjQgxgQRtERdauqw43V4WzMu56s/TjXoWzsumpctK7+BIjEY3e9nsbowGLXpddH9VmFL13FqZ\nz2XLMG09kkUuhJ8EbREXrj3Pnqim2r9FLqvtaLNGse74te5cWgTAO3WyRS6EnwRtERca/UF73vVB\ne8XYufYJ2SKPKlVVsTncUb3uNdHyyjzSjTrePduN1yc16IUACdoiDvh8KufbByjMSSXblHLd53My\nUqiYk0lj22DgjFVEnsvtw+3xYYpSCdNr6bQa1iwuZGjYxZkmqUEvBEjQFnGgtceKw+m94Srbr6ba\njE9VqZUs8qix+kuYxmh7HGDt2Bb5kTOyRS4ESNAWccDfirP6BufZfoFzbdkijxprlDt83UhFcSaF\nOakcb7TgcHpiNg4h4oUEbRFz/qC9oDTnpo8pyk1jTn46Z5r7cLqkkUQ0xOq610SKorB2aRFuj48P\nGnpiNg4h4oUEbRFTPnX0PDs/y0helnHSx66sysft8VHX1Bul0c1ugWpoMVxpA9y5ZGyLXLLIhZCg\nLWLrsmWY4RHPDa96XUu2yKPLGuVe2jeTn51KdWk251oHuDLoiOlYhIg1Cdoipvz9s6snSULzm1+U\nQW5mCicv9OLxyhWgSLMFSpjGdqUN4wlp757pjvFIhIgtCdoipgJFVebd/DzbT1EUVlaZsTs9gXNw\nETmxaBZyM6sWFKDTajhyRsqaitlNgraIGVVVaWwbICcjBXOQ82w/qY4WPf7t8VifaQOkGXWsrMqn\ns9dOc5c11sMRImYkaIuY6ei1Y7W7WVCajaIoIX1NdWkW6UYdJxot+GTFFVE2uxsFSDfqYj0UYHyL\nXMqaitlMgraImcYpnGf7aTUaVtySz4DNRVPnUKSGJhhdaacZdWg18fFrYkl5Lhlpet472y05DWLW\nCvoW2ufzsW3bNhoaGjAYDOzYsYOysjIALBYLW7ZsCTy2vr6erVu3smnTJh588EFMJhMAJSUl7Nq1\ni5aWFr761a+iKApVVVV861vfQhMnvxBE9E3WJGQyNdVmDtd1cbzRQuWcrEgMTQA2uwtTlPtoT0an\n1XD74kIOftBO3aU+VlTlx3pIQkRd0Ih58OBBXC4X+/btY+vWrezevTvwObPZzN69e9m7dy9btmxh\n8eLFPPLIIzidTlRVDXxu165dAOzatYsvfelL/PjHP0ZVVV577bXIzUzENVVVaWgbIDPdQFFu2pS+\ndkl5Lga9hhONUtI0Unyqis3hISMOktAmGt8i74zxSISIjaBB+9ixY6xbtw6AFStWUFdXd91jVFVl\n+/btbNu2Da1Wy7lz53A4HDz22GNs3ryZ2tpaAM6cOcOaNWsAuOeee3jnnXfCOReRQHr6HQzaXFM6\nz/Yz6LUsLc+jq89Ox5XhCI1wdnM4PfhUNS4yxycqK8xgTn46tRd6GR6R5jFi9gkatG02W2CbG0Cr\n1eLxXF0D+PXXX6eqqoqKigoAjEYjjz/+OP/6r//KP/zDP/B3f/d3eDweVFUN/IJOT0/HapUs0Nmq\nYZJWnKGoqR7dGk3WQis+X2yT7PzXveLhjvZEiqJw55JCPF4f75+TsqZi9gl6pm0ymRgeHl/N+Hw+\ndLqrv2z//v1s3rw58HF5eTllZWUoikJ5eTnZ2dlYLJarzq+Hh4fJzMyc9LVzctLQ6bQhTyZUZnNG\n2J8z1hJtTs09NgDuWD530rHf7HMfuT2Ff//1OU419fEXDyyLyBgjJdj3qrG1n6/tOcwXH1nJupVz\nozSqq/UOjwbtgrz0kP5tRfPf3yfX3cJLhy7xQYOFh9cvjOhrJdrPVSiScU6QvPO6VtCgXVNTwxtv\nvMEnPvEJamtrqa6uvu4xdXV11NTUBD5+8cUXaWxsZNu2bXR3d2Oz2TCbzSxevJj33nuP22+/nUOH\nDnHHHXdM+tr9/fZpTGlyZnMGFktyrfATbU6qqnLqvAVTqh6jlpuOPdi8FszL5mxzPw0XLeRmhnbP\nO9ZC+V7928unGXF5ea+ug4Ulk7+xjZS2jkEAtNz8++MXi39/C+flcLapjzPneyjITo3IayTaz1Uo\nknFOkHzzmuwNSNDt8fXr12MwGNi4cSO7du3iySef5MCBA+zbtw+Avr4+TCbTVeeSDz30EFarlU2b\nNvHlL3+ZnTt3otPpeOKJJ/je977Hhg0bcLvd3H///WGYnkg0VwZH6BtyUl2ajWaK59kT+QutnEii\nHtuNbQOcaR69CtfTH7s621ZH7HtpTyZQ1lTubItZJuhKW6PR8NRTT131Z5WVlYH/zs3N5eWXX77q\n8waDge985zvXPVd5eTnPP//8dMcqkkTjNK96XWtllZnnf9vI8UYLH7mtJBxDi7lfvnUJAL1OQ3cE\ndppCFS8dvm6mptrM3lcbeOdMF5++a/6UkxmFSFRySVpEXaB/9jST0PxyMlIoL86koXUg0Ps5kZ1r\n6edc6wBLK3KpnJNJ35ATlzs2vcPHO3zFZ9BOTdFRs8BMT7+Dix1SZEfMHhK0RdQ1tPWTlqKjxGwK\n/uAgaqrz8akqJy8k9ha5qqr88u0mAP7w7goKx+6u9wzEZos83lfaAGulz7aYhSRoi6jqGxrBMjBC\nVUkWGs3MtzSTpcd2fUs/jW0DLK/Mo2JOJoU5o0G7uy9GQTvOV9oAi+bnkGUycLS+G7dHypqK2UGC\ntoiqqbTiDEVxXjrFeWmcaerDGaOt5Jm6apW9rhyAwpzRjOieGJ1rWx0utBqF1JT4aBZyI1qNhjsW\nFzI84uHUxd5YD0eIqJCgLaIqXOfZE9VUm3F5fNRd6gvbc0bTmeY+LrQPsrIqn/lFo1e8CsaCdneM\nMshtdjemVH3cJ3itXVoMSFlTMXtI0BZR1dA2gNGgZV7hzM+z/RJ5i1xVVX751ugq+4G7ywN/XpCT\nikLsVto2hzuuz7P9SgtMlJhNnLrYmxTJiEIEI0FbRM2gzUl3n51bSrLC2u5xflEGORkpnLxwJeFa\nNp6+1MeljiFuqzYzr3C8oIJepyU3MyUmK22vz8fwSPw1C7mZtUuL8PpUjtZ3x3ooQkScBG0RNdNt\nxRmMoiisrMrH7vQE7oAngtFV9ui97ImrbL+CnDT6rc6on9UPO0Z7C8RrYZVr3bGkEEWRLHIxO0jQ\nFlET7iS0iRJxi/zkhV6au6ysWlhAScH1xwWBa19RXm1b7WPV0OKol/Zksk0pLJmfy8WOIbr6YleQ\nRohokKAtoqaxdQCDTsP8ovAX9q8uzSbdqOPE+Sv41Nh2yArFaMb4JRTggbvm3/Ax/gzy7igHIv/Z\ncKKstAHuXCp3tsXsIEFbRIXV7uLylWEq52ah04b/n51Oq+HWW/Lptzpp7oz/xgEnzl+htdvGmsWF\nzL1JkZnxDPLoBm2rPf7vaF+rpspMikHLkTNdCfGmTYjpkqAtoqJxhv2zQzHeQCS+t8h9YxnjigKf\nuckqGwgUWIn29nhgpZ0A2eN+KQYtq6rNXBkc4UL7YKyHI0TESNAWURGpJLSJlpTnYtBp4v5c+3iD\nhXaLjTsWF1Kcl37Tx5mzU1GU6N/VDtQdT6CgDeOdv+TOtkhmErRFVDS2DqDTaqiYE7n+0Cl6LUvK\nc+nstdPZOxyx15kJn0/l5bdHV9mfvuv6jPGJ9DoNeZnGqG+P2wLb44mRiOa3oCyHnIwU3j9niVmj\nFSEiTYK2iLjhETdtPTYq52Si12kj+lrxnkV++GQHl68Ms3ZJEUVj2eGTKcxJZdDmYsTlicLoRtni\nvJf2zWgUhTuXFOFweqhN8AYyQtyMBO041N1n5wcvnaZvaCTWQwmL822DqIxmeEfarbfko1EUjjfG\n3y9tn0/lJ787h0ZR+PQkZ9kTFcTg2pc1Ac+0/SSLXCQ7Cdpx6HBdF8caLfz3kZZYDyUsGtr6gcgm\nofmZUvUsmJdNU+cQ/VZnxF9vKo7Wd9PWbWPtsiIKcoKvsgEKs6Nfg9xqd2PQaUjRR3ZXJBLm5qdT\nVpTB6Ut9DA27Yj0cIcJOgnYcau0evbL0zunOpKin3NA6gFajUDk3KyqvF49b5F6fj5cPN6PVKHx6\n7fyQv258pR29c22bPTHqjt/M2iVF+FSV96SsqUhCErTjUMtY0HZ5fBw62RHj0cyMw+mhpdtKeXFm\n1FZuK6vygfgK2u+d7aa7z85H18zDPLZ6DsV4gZXorbRtDnfCnWdPdPviQjSKwjuyRS6SkATtODNg\nczJoc7GgNJsUvZbXjrUnXBOMiS5cHkRVo7M17pebaaS8OIOG1oG42Knw+nzsf3t0lf3IR6un9LXj\n176is9J2ub043d6EKqxyrcx0A0srcmnpsnL5SnzeIhBiuiRoxxn/1viishzuXlZMv9UZVyvGqQr0\nz45CEtpENdVmfKrKqYuxT0h7p66LngEH99w6J+SzbD+dVkN+ljFqZ9rjhVUS67rXtdZKQppIUhK0\n40xL12jQnleUwUdXlQDwu/fbYjmkGWlo60ejRO88229llf9cO7ZB2+P1ceBwMzqtwifvLJvWcxTm\npDE07MLM9D6CAAAgAElEQVThjPy1L3/QTuSVNsCKW/JJTZGypiL5SNCOM63dNgDKCjMozE3j1so8\nLnYMcfFy4pVmdLq8NHdaKSsykZqii+prz8lPpyg3jbpLvVFvbTnRO3VdXBkc4d5b55KbaZzWc0Sz\nnGkiX/eayKDXsnphAf1WJw0t/bEejhBhI0E7zrR0W8lM05NtGt2eXL+6FIDffZB4q+0LHYN4fSoL\nSsPfijMUNdVmXB4fZ5r6YvL6o6vsJnRaDZ+Y5iobots4xJaAzUJu5s4lY2VNz8gWuUgeErTjiM3h\n5srgCPOKMlAUBRg9255rTueDc5aEK7biP8+ujmIS2kSBBiIxygl4+1QnvUNOPrRyDjkZKdN+nsLc\n6N3VTpYzbYCq0mzys4x80GCJ6W6LEOEkQTuOtI0loZUVjvebVhSF9atK8akqrx+/HKuhTUtj2wAK\nUF0S3fNsv/nFGWSbDNReuILXF90MfLfHx4F3mjHoNHzyjumvsmHC9ngU+mpb7YlZwvRGNIrCHUuK\ncLq8MXvjJkS4SdCOIy0TzrMnumNxIaZUPb+vvZwwKwa3x8uljiFKC02kGWMTADSKwspqM8MjHhrH\nVv3RcuhkB/1WJx+umUuWafqrbIC8LCMaRYnKStuaJIlofuOdv2SLXCQHCdpxxF9UZV7R1UHboNfy\noZVzGR7xJMwVlksdQ3i8vpidZ/uNV0eLXha52+PlV0eaMeg1/MHtM1tlw9i1r+zodPvyn2kneiKa\nX1FuGhVzMjnT3MeALb7K2goxHRK040hLl5XUFB3mrOuzjD+8ci5ajcLvPmhLiCssgfPsKN/PvtaC\n0mzSjTqOn7egRunv7c3aDgZsLj5SU0JmenjOhgtz0rDa3dhHInvtK3CmnSQrbRhdbasqvHtGypqK\nxCdBO06MuDx099kpKzQFktAmyslIYc2iAjp77ZyNUTb0VDS0+YN2bM6z/XRaDcsr8+m3OmkeuwMf\nSS63l18faSHFoOXjt88L2/NGK4PcaneTmqJDp02eXw1rFhWi1SgckSzysPP6fHRI1bmoSp6fzATX\n1mNDBeZdc549kf/612/j/PqXx+vj4uVB5prTyYiDLOSa6ujVIn/zxGUGh1189LaSsM7dX4M80ne1\nbQ5X0pxn+5lS9SyvzKOtx0Zbjy3Ww0kKbo+P39de5u+fe5ev/7/3eO+s7GJEiwTtOOGvhFZWdPOg\nPb8ok6qSLOou9cX1u9vmTisujy/qpUtvZml5HnqdJuJB2+ny8ut3WzAatNy/JnyrbIDCsW5fkVxp\nq6o62iwkSc6zJ5KypuHhcns5+EEbX/3/jvCjVxoC7W/fON4e45HNHhK040TLDa573cj6VaOr7YPH\n4veHZLx/dmyT0PxSDFqWlufS2Wunszdyb3ZeP9HOkN3N+lWlYT8Tjka3rxGXF49XTarzbL/llfmk\nG3W8e7YrarkNyWTE5eGV91r5yg+P8OOD5xl2uPnY6lKe+fxaFpXl0Ng+SFcUriQKCdpxo7XbhkGv\noSh38oYSK6vzycs0xnWv7XhJQpvIn0V+5ExXRO5sj7g8/ObdVlJTdHxsTWnYnz8vy4hWo0S0r3ay\nXfeaSK8bzW0YsLkCpYJFcPYRDwfeaeYre47wszcu4HJ7+eSdZfzjX61l40eqyMlIYd3yYgAOn+6M\n8Whnh+gWhBY35PZ46bgyzPziDDSa65PQJtJqNHzkthJ+9sYFDp3s4BMzLNwRbl6fj/OXBynKTSMr\nTJnT4XDrLfloNQr//U4Lvz3axrzCDOYXZ1BelMn84tE675obJACG6rVj7dgcbh64u5z0CNxL12o0\n5GenRvSudrJd97rW8so8jpzp4vSl3kmPocToLYLfvt/Ga8facTg9pBt1PHB3OR9dVXLdv++aajOp\nKToOn+7kD9eVo9XIWjCSJGjHgXbLMF6fGnRr3O+eW4t5+e0mXjvWzsdWh39VNxMtXTacLm9U+2eH\nwpSq568/u4wTjRaau6xc6hjiwoQmLEaDlvlFGcwvzmR+UQblxZnkZxlvmMl/LYdzdOswLUUXOL6I\nhMKcVE712RkecUfkjYHNkTzV0G5kSXkuigKnL/XyqbXzYz2cuDRoc/Lq+228cXy0kFNGmp6HPlTJ\nh1fOvWnTH4Neyx2LC3njxGXONPWxvDI/yqOeXSRoxwF/D+3JMscnSjPquXtZMa8db+d4o4VPFsX2\nWtVEgfPsONoa91txSz4rbhn9heJ0e2nrsdHUOURzp5XmriEaWgc4N6FymilVPxbIM5hflEl5cSbZ\nJsN1gfzgsXaGRzw8uK6cNGPkfqQKJmSQlxeHP7Ba/c1C4iDjPxJMqXoq52Rx4fJgxN74JKq+oRF+\n814rh0524Pb4yDYZePCeCu5dMYcUvTbo19+9vJg3TlzmrVOdErQjTIJ2HLhZ+dLJfHRVCa8db+d3\n77fxyXtuidTQpsxfLjRektBuJkWv5Za5Wdwyoc+3w+mhpctKc5d1NJh3DVHX1EfdhHvxWekGysdW\n4/OLMynKTeXV91pJN+r4aARX2TBeg7y7z055cWbYnz8ZC6tca1lFLhcuD3KmqY81iwpjPZyY6xlw\n8Jt3W3j7VCden0peppFP3FnG3cuK0OuCB2u/+UUZlJjTqT1/hSG7i8wkfeMXD4IGbZ/Px7Zt22ho\naMBgMLBjxw7KykbPUS0WC1u2bAk8tr6+nq1bt7Jp0yYAent7+exnP8u//du/UVlZyZkzZ/jWt76F\nwWBg0aJFfO1rX0Mj5x+0dFnRahTmmtND/hp/r+2TF3tpaOkjNw7OIX0+lcb2QQqyU2fU1SpWUlN0\nLCzLYWHZ+BsOm8NNc9cQTZ1WmjuHaO6yUnvhCrUXri6L+kf3VkS8Z3iku335g3ZGHPxbipTllfn8\n11tNnL7YO6uDdmfvML860sK7Z7rxqSoFOal88s4y7lxSNK3COoqisG75HH7y2nnereviY2G+8ijG\nBf0tc/DgQVwuF/v27aO2tpbdu3ezZ88eAMxmM3v37gXgxIkTPPvsszzyyCMAuN1uvvnNb2I0jpfk\n/MY3vsHXv/51ampqePbZZzlw4AAPPPBAJOaVMLw+H+0WGyVm05R/WNavLuXkxV72v3WJP79/QYRG\nGLq2HhsOp4fbFphjPZSwMaXqWVqex9LyvMCfDdicgS315i4rPp/KR24rifhYAivtCGWQ+7fHk3ml\nXVpoIjPdwOmmPnyqOqPkw0TU3DnE3l+d4f36HlRgbn46n1xbxpqFhUGTYIO5Y0khP3vjAm+d6mT9\n6tKQ8kHE1AUN2seOHWPdunUArFixgrq6uuseo6oq27dv59vf/jZa7eiWyjPPPMPGjRt57rnnAo/r\n7u6mpqYGgJqaGl577bVZH7Q7e+24PT7mFZqm/LX+XtuHT3bwmTvLyM28vmZ5NPlLl8bjeXY4ZZtS\nWFGVwoqq6J7d5WUa0WmViN3VHl9pJ+/WpkZRWFaRy+HTXbR2W5lfFP5jhnj1y7cusf9wMwDzCk18\neu18Vlabw/bGJSPNwMqqfD5oGE32jMQRjgghaNtsNkym8YCi1WrxeDzodONf+vrrr1NVVUVFRQUA\nL730Erm5uaxbt+6qoF1aWsrRo0dZs2YNb7zxBg7H5L98cnLS0E3hXCVUZnP8XPc43TKauLXkFvO0\nxvXZD1fxvZ/V8l6Dhc2fWBzu4U1J81hC3Z0rSjAHuW8eqnj6XoXLTOZUlJeOZcARkb8Xp8eHRoF5\nJTlop7jqSqTv010rSjh8uotLXTZWL5s76WMTaV6T6R108Ot3W8jPTuWvH7qV2xYWRGQl/Ml1lXzQ\nYOGDxiusWT753224Jcv3KpigQdtkMjE8PF5FyufzXRWwAfbv38/mzZsDH//iF79AURSOHDlCfX09\nTzzxBHv27GHnzp08/fTT/OAHP2DVqlUYDJO/o++PwDag2ZyBxRL5xhGhOn1+tLRmXrp+WuNaUppF\nZrqBXx9u4r4QMz0jwaeqnL5whbzMFDReb1j+juPtexUOM51TXkYK7T02mlr7wr6N3TfoIM2op693\nasVHEu37VJqXikZROHK6g/tWzLnp4xJtXpP5+ZsX8HhVNq6vpiw/jStXIlNgpjR3NJ/lzeNtfGZt\nWdR+H8Xqe+X1+ahv7qe6NBtDGOc62RuQoIeoNTU1HDp0CIDa2lqqq6uve0xdXV1g2xvghRde4Pnn\nn2fv3r0sWrSIZ555BrPZzO9//3u+/e1v86Mf/YiBgQHuuuuu6cwnqbR221AUKCmY+vY4jN6R/IM7\n54/22o5hF6MOyzDDIx6qY9w/O9lFsga51e5O6iQ0v3Sjnsq5mVzqGIrbqoLh5HB6ePNEB5npBj58\nW2RvOGg0CmuXFuFweqPSoCeWVFVl76sNfPdnJzl5sTdqrxs0aK9fvx6DwcDGjRvZtWsXTz75JAcO\nHGDfvn0A9PX1YTLduJ3ktcrKyvjzP/9zNm7ciMlk4t577535DBKYT1Vp7bZSnJc+o3ekf7B2/miv\n7ffbYlZXOXCeHWdFVZJNoNtXmM+1fT6V4RF3UiehTbS8Mg9Vhbqm6P2yjZVDJztwOD185LaSsK4G\nb+busbKmb59K7rKmr7zXyqGTncwrNLGsIjdqrxt0e1yj0fDUU09d9WeVlZWB/87NzeXll1++6df7\ns8sB7rvvPu67777pjDMpWfodjLi8lE0jCW2ivKxU1iwq4MiZbs40912V6RwtErSjoyBCK22704Oq\nJnfm+ETLKvL4xe8vcfpiH3csLor1cCLG4/Xxuw/aSNFr+fDK6JwxF+aksaA0m/qWfnoGHBRkp0bl\ndaPpg3M9/PzNi+RkpPC3D92K0RC9kidySTqGQu3sFQp/r+3fvR/97l+qqtLY2k+2yZCUP6DxJNDt\nK8x3ta320RKms2F7HKC0wESWyUBdUy++JO769X59D31DTtYtL47qGzL/avtwEq62L14e5F/++ywp\nBi1/+9DyqNekkKAdQy1TLF86GX+v7dOXeiPafvJGuvrsDNndVJdmy93MCMvNNKLTaugOcxvE2XDd\nayJFUVhWkYfV7g70sk82qqrym/daURSi3qNg1YICjAYth+s68fmS501Rz4CD//OLU3i9Kv/rgaVh\n+d09VRK0Y6i1yx+0Z7Y97hfotf1BdFfbDQlSujQZaBQFc7aR7n5HWPMXbLOgsMq1lleMHiOdimIS\nUTSdae6j3WJj9cIC8qO8A5Zi0LJmUSF9Q07OtvQF/4IEMDzi5p9/fhKr3c2frK9ieWX0jyFBgnbM\nqKpKS7eNguxU0sLUuMDfa/twXXR7bc+WoirxojAnDYfTE9bvsXUW1B2/1uL5uWgUhdOXkjNov/Je\nKwAfvz02JUXXJVFCmsfr4wcvnaaz1879a0r5cE3kKyDejATtGOm3OrE53MwLY19ff69tl9vHWyc7\nwva8k1FVlca2ATLT9BTnhaegiphcJGqQz7YzbYA0o45bSrJo6hhiaGz+yaKly8rZ5n4WzsuOWdW3\nijmZFOelcbzRktBX61RV5UevnONc6wA11WYe/nBsGzRJ0I4R/znaTDPHr3XPrcWk6LUcPNaOx+sL\n63PfiGXAQb/VKefZUTSx21e4jHf4mh1n2n7LK/NQgTNNybGF6/fqUf8quyxmY/A3EfF4Vd472x2z\ncczUfx9p4fDpLsqLM/jcpxfHvF69BO0YCWfm+ET+Xtv9VmdUihvIeXb0RSKDPHCmPYtW2jB69QtI\nqi3yK4MOjtb3MNecHtX7wzdy59IitBolajt/4fbu2S7+69Al8jKNfPGPlses4uREErRjpKUrfJnj\n1/roqtHzlt990Bb2557owuVBfjeW9Cbn2dHjr4rWE8a72v4z7YxZdKYNUGJOJycjhbpLfUmT5fy7\n99vxqSofXzMv5rtfWekGllfm0dpjS7gs/ca2Af7tV/Wkpmj50sPLyTLFR7thCdox0tpjIycjhcz0\n8G9H+nttX7w8xMWOwbA/f0uXlX/6+Ul27j1Gu8XGmkUFzJlCL3AxM9kZKeh1mrB2+7I53Gg1CkZD\n7FcS0aSMdf2yOdw0dQ3FejgzNjzi5tDJDnIyUrh9cXz0C1+3fLS+eyIlpHX32fn+S6dRVfirB5cx\n1xzeY8yZkKAdA4PDLvqtzrBvjU/kL7YSzutfly02fvBfp/mH/3ifUxd7qS7N5qt/UsPnH1ga83Oe\n2USjKBRkp9IzYA/btS/bWN3xWK/MYmFZxWiL1dNJcPXrzROXcbq9fHRVCTptfPx6X1aZS1a6gXfP\nduH2eGM9nKBsDjf/9POT2BxuHr1/AUvmx/aI4Vrx8V2dZVq7w3s/+0b8vbY/ONdD39DIjJ6ru9/O\ncwfO8M1/PcqxBgvlxZls3bCCJ/54JdWyLR4TBTmpOJxerPbwZOVaHe5Zl4Tmt3j+aCvSRD/Xdnt8\nHPygHaNBy723Rrct5mS0Gg1rlxYxPOLhxPkrsR7OpNweH9//xSm6+x184o4y7rn15l3gYkWCdgwE\nMsfDeN3rWoqisH5VKV6fyhsnLk/rOXoHR/iP39Tztefe490z3ZQUmPjiHy3n65tvY0l57qxclcWL\ncHb78nh9OJyeWXXda6LUFB1VJVk0dVoZGk7cq1/vnulicNjFh1bMJc0YvVrYofCXNX0rjrfIVVXl\n339TT2P7IKsXFvDZeytiPaQbkqAdA60Ryhy/1h2LCzGl6gNbZqEasDl54beNPPncEQ6d7KQwN5X/\n9YdL+dZfrGZFVb4E6zgQyCAPw7n28CwsrHKtZWPVrRK165dPVXnlaCtajRJIRI0nxXnp3DI3i7NN\nffQOzmznL1JefruJd890Uzk3k8c/uShuj/wkaMdAS7cVU6o+4oXmDXotH1o5N+Re21a7i5+9foEn\nfniE1463k5ORwv/41CK2P347qxcWxO0/4tkocFc7DCtt6yy97jVRopc0PXWxl85eO7cvLiQ30xjr\n4dzQ3cuLUYHDp+NvtX34dCf7DzdjzjbyhT9aHpUWptMlQTvK7CNuLAMjlBVlRGXF+uGVc4P22raP\nuHnp0CW+8sMjvHK0FVOqnj/7+AKe/twdrF1ajEYjwTrejG+Pz3ylPVuve000Jz+d3MwUzjQl5tWv\nQMnSNbEpWRqK1QsLSNFreft0Z1x1VjvX0s9//OYcaSk6vvTwrWTGedOc+Dr4mAVau21AZJPQJsrJ\nSGH1ogLevUGvbYfTw8Fj7bz6Xit2p4fMdAOfvaeCD62Yg14Xv+80BWSZDBh0GnrCUBXNJtvjKIrC\n8oo83qzt4FLHELeUZMV6SCG71DFEY9sAS8tzKSmIn6tJ10pN0bF6YQFvn+6koaWfRXGQld3ZO8z3\nXzoNwN98dhnFefF/dVVW2lEWqUpok/F3//L32na5vbzyXitP/PAI/3XoEooCD3+okmf+552sX1Uq\nATsBaBSFgpxUugdm3u3LNlZ3ezZvj8N4dbRTCZZF/sp7LUDsGoNMRSAhLQ62yIfsLv7p5yexOz38\n+R8sZGFZYlR1lJV2lAWCdgQzx69VXpzJLWO9tn/51iV+f7KDQZuL1BQtf3h3OetXl5KaIv8UEk1h\nThrtlmGGhl0zqtY0vj0e39uCkbawbOzq18VePntPfGYOX6un386xRgvzCk0sSoCgU1WSRWFOKsca\nLNjXu8PW4XCq3B4v3/vFKSwDI3zmrvnctaw4JuOYDllpR1lLl5XUFC3mKPe3/djYanv/4WYcTg+f\nvLOMZz6/ls/cXS4BO0EVhKnbl7/u+Gy98uWXmqKjujSblm4rgzZnrIcTklffb0NVR1fZiXCrQ1EU\n7l5ejNvj4736npiMwaeq/L//rufi5SHuWFzIA3eXx2Qc0yVBO4qcLi9dfXZKCzKinom9sjqfu5cV\nc/+aUv7x82v5o3srZ/UZZjIIV7cvOdMeN95AJP67flntLg6f6iQv08jqhQWxHk7I1i4tRlHg7VOx\naSLyX4cu8f65HqpKsviLTyxKiDc7E0nQjqI2iw1Vje55tp9Wo+GxTy5iw31VEal3LqIvXN2+rBK0\nA5ZXJk7Xr9ePX8bl8fGx1aVoNYnzqzwnI4VlFXk0dVpp77FF9bUPnezgV0daKMxJ5Qt/tBy9LnH+\n3vwSb8QJbLwSWvxmeIrEURCmu9pWu4sUvTau76ZGS3FeGnmZRs409eGNQj/66XK6vbx2rJ10o451\ntybOeayfv4lINCuk1V3qZe+rDZhS9Xzp4VsT9k2qBO0oGq85Hv2Vtkg+2SYDKXotPTM903a4E/YX\nWLgpisLyyjzsTg/nWvpjPZybeud0JzaHmw+tnIvRkHg5KbfekkdGmp4jZ7rwROHN0aGTHfzzi6dQ\nlNGrXf46B4lIgnYUtXRb0es0FOcl7j8YET+UsWtfPf0zu/Zls7tn/XWvifzn2sfOdcd4JDfm86m8\nerQNnVbho7fFX8nSUOi0Gu5cUoTN4aY2gk1EfD6Vn71+gf/4zTmMBi1bN6xI+CZHErSjxO3xcdky\nTGmBKaHOn0R8K8xJxen2MmCbXqMLp9uLy+Ob1dXQrrWoLAedVuFYjLKbgzlx3kLPgIO1S4tmdNUv\n1vx3tt+O0J3tEZeH7790mleOtlKUm8bX/2wVC+bF/7W4YCR6REnHlWG8PjUmSWgiefm3+Xqmea5t\nk7rj10kxaFlQms2ljkH6rfF19UtV1UDJ0vvjuGRpKErMJsqLMzl9qTfsf899QyPsev44tReusHh+\nDl/bfFvgtkWik6AdJS1R6KEtZp+CGWaQy3WvG1tWmQ+MJi/Fk/Ptg1zsGGLFLfkJUXIzmHXLi1FV\neKcufKvtps4htv/oA9p6bHxo5Vy+9PCtpMeoiEskSNCOklhUQhPJb6Z3ta2O0W31jDhvkhBtyypG\n62LH29WvQGOQBChZGoo1iwox6DS8dapzxuV4AY7Wd7P7heMM2V1s+mgVj36sGp02ucJccs0mjrV2\nWdFqFObmy0pbhI//rvZ0M8gD1dBkpX2Votw0ivLSONPcF5Xs5lB09g5Te+EKFXMyqUqghiaTSTPq\nuG1BAT39DhrbBqb9PKqqcuBwEz98+QxajcLfPrSc9atKE65wSigkaEeBz6fS1mNjbn56Ql7mF/Er\nM91AikE77bvaUljlxhRF4baFhTicXi5eHoz1cAB49eh4+81kCkbr/Alp07yz7fZ4+e6Pj/NfbzWR\nl2nk7//0NpaPHW8kI4kgUdDZZ8fl8cn9bBF2iqJQOHbtazo9iq1Sd/ymVi0qBOKj69egzck7dV0U\n5KRSU22O9XDCqnpeNuZsI+839OBweqb0tUPDLv73T2p583g7lXMy+fqfrYrr9qThIEE7Clq75Dxb\nRE5hThouj4+BaWTgSiLazS2tzEOn1XD6YuzrkB881o7Hq3L/6lI0muRZZcNom9m7lxXjcvt4/1zo\n1+zaLTZ2/OcHXLg8yD0r5/KVP15J1iwo0SxBOwpi0UNbzB6FM+j2Nd5LO/l/2U2V0aBjYVk27RYb\nfUMjMRvHiMvDmycuY0rVJ1QLyam4a1kxCvBWiE1ETl3sZefeY1wZHOEP15Xzd39yG3rd7CjDK0E7\nClq7rShASUHiX9EQ8adwBjXI/SvtdGPilcKMBn91tLqm2K223zrZyfCIh4/cVpK09eFzM40sKc/l\n4uUhOq4M3/Rxqqpy8IM2/vnFk3h9Kp9/YAmfuas8qc74g5GgHWE+VaWl20pRXlpC1ggW8c9/V7un\nb+orbavDTVqKLumuxYTL8rGgfepibM61vT4fv32/DYNOw301c2Myhmi5O0hCmsfr4/nfNvLjg+fJ\nSDPwxB/XsGYs72A2kZ/UCLsy4MDh9MrWuIiYGa207W5JQptEYW4aBTmpnI3R1a/3z/XQOzTCXcuL\nk/4u/coqM+lGHe/UdV73d20fcfPPPz/JGycuU2I28Y3Nq6iYkxmjkcaWBO0Ia+0e7RcrmeMiUjLS\n9KSmTL3bl6qqox2+JGhPallFHiMuL+fbo3v1y1+yVFHg/tWlUX3tWNDrRpuIDNndnJ6ws9HTb+fp\nvcc409zPilvyefJPa8jLMsZwpLEVNGj7fD6++c1vsmHDBh599FFaWloCn7NYLDz66KOB/61atYqf\n/OQngc/39vZy7733cvHiRQDq6+t55JFH2LRpE08++SQ+X3wULYik8SS05L6GIGJntNtXGj0DU7v2\n5XB68fpUMlKTewU3U8srR7fIo10drb6ln9ZuG7dVmwO905Odf4vc32e7sW2AHf95jM5eO/evKeVv\nPruM1JTZfcwYNGgfPHgQl8vFvn372Lp1K7t37w58zmw2s3fvXvbu3cuWLVtYvHgxjzzyCABut5tv\nfvObGI3j74i+//3v89d//df85Cc/weVy8eabb4Z/RnGmZey61zy57iUiqDAnFbfHR/9Q6Ne+/CVM\n5brX5BaUZqPXaaIetAONQZKkZGko5hVmUFaYwamLvbzyXiv/+ycncDg9/NnHF7Dhvqqku+42HUGD\n9rFjx1i3bh0AK1asoK6u7rrHqKrK9u3b2bZtG1rtaHbjM888w8aNGykoKAg8btGiRQwMDKCqKsPD\nw+h0yf2OSR1LQsvPMiZVwXoRf6Zzri0dvkJj0GtZVJbDZctw1K5+tfXYqGvqo7oki8o5yVGyNFR3\nLy/Gp6r87I0LGA1atmxYwb0rkjsJbyqCRk2bzYbJNL61q9Vq8Xg8VwXc119/naqqKioqKgB46aWX\nyM3NZd26dTz33HOBx82fP5+nnnqKPXv2kJGRwe233z7pa+fkpKGLwN07szk6q97eQQdWu5uly/Ij\n/prRmlO0JeO8IjGnW8py4J1m7G5fyM/fZBm9WlOUb5rxmJLx+wTj87pz+RxOXeylqWeYBZWRr0j2\n/MHzAGz42MKw/93G+/fqU/dUsv9wMxlper75P+5grjm0o8V4n1e4BA3aJpOJ4eHxe3M+n++6FfL+\n/fvZvHlz4ONf/OIXKIrCkSNHqK+v54knnmDPnj08/fTTvPDCC1RVVfHCCy+we/duvvWtb930tfun\nWc2SzioAABP9SURBVE95MmZzBhaLNezPeyO1568AUJSTGtHXjOacoikZ5xWpOaWO1bS/2NaPxRJa\n3eXLnUMAKD7fjMaUjN8nuHpe5WM5Ke+cvMxtt+RF9HVPnLfw++PtFOelUWZOC+vfbaJ8r57+3O0Y\nDVp0qCGNN1HmFarJ3oAEDdo1NTW88cYbfOITn6C2tpbq6urrHlNXV0dNTU3g4xdeeCHw348++ijb\ntm3DbDaTlZUVWLUXFBRw/PjxKU0k0UglNBEt/m5f3VO4qx0oYSrb40EVZKdSmJvG2ZZ+3B5fxBr/\nHDrZwY9eOYdep+FPP7YAzSwqGjKR5FncXNCgvX79eg4fPszGjRtRVZWdO3dy4MAB7HY7GzZsoK+v\nD5PJFFJFmh07dvDlL38ZnU6HXq9n+/btYZlEvGqRmuMiSkypetJSdFM60w700pbs8ZAsr8jjdx+0\ncb59gMXzc8P63Kqq8qsjLbx06BKmVD1/+/DyWXeWLUITNGhrNBqeeuqpq/6ssrIy8N+5ubm8/PLL\nN/36vXv3Bv571apV/PSnP53OOBNSa4+VLJNhVhSxF7GlKAqFuam09djw+dSQsmxt0uFrSpZV5vK7\nD9o4fak3rEHbp6r85OB5XjvWTl5mCls2rKA4T0oeixuT4ioRMmR30TfklK1xETWFOWl4vGrIGc6y\nPT41C0qzMeg1YS1p6vb4eG7/GV471s5cczp//+gqCdhiUhK0I6RVzrNFlPlrkIfa7cvqcKNRlFlf\nrCJUep2WRfNy6Oy1c2Vg6nXer+Vwevinn5/kaH0PVSVZfPVPasjJSAnDSEUyk6AdIVK+VESb/652\nT4jn2la7G1OqbtYmO01HuKqjDQ27+Mcfn6C+pZ+VVfls3bBCajmIkEjQjpDxJDQpXyqio2CKfbVt\ndpf00Z4if6vO05em36qzZ8DBzueP0dJt5Z5bi/mrB5cmbctNEX6yLxYhLd1W0o068jJnb2F7EV2B\nqmh9wVfaXp8P+4gn5MIVYlR+dirFeWmcbenD7fGin2Lxp9ZuK9/92UmGhl18au18Hlw3u3pBi5mT\nlXYE2Ec89PQ7KCvKkB9IETWmVD3pRl1IK+3hEQ8qkCH3YadsWUUeLrePxrapdf2qb+ln9wvHsQ67\n+JP11Xz2ngr5/SCmTIJ2BLT1jDUJkfNsEWWFuWlYBhx4g3TQk7rj07ds7Fx7KlnkH5zr4dmf1eL2\n+PifDyzhI7eVRGp4IslJ0I6AlrEkNMkcF9FWmJOK16fSG6TbV+C6l6y0p6y6JJsUvTbkZLQ3jrez\n55d16LQavvzIraxZVBjhEYpkJkE7AqQSmogVf9/lniDn2tZAYRVJRJsqvU7DorIcuvrs9Exy9UtV\nVX751iX2/raRjDQ9T/xxTdgrqYnZR4J2BLT2WEkxaAP3ZoWIlsIQ72rbAiVMZaU9HYGrXzfZIvf5\nVP7z1Qb2H27GnG3k7x+9Td7Ei7CQoB1mTreXjivDzCswyf1XEXWFuaH11bbKmfaMjF/9uj5ouz1e\n/u8v6/h9bQfzCk38/aOrAjsgQsyUXPkKs3aLDVWV82wRG/6Vdk/Qlbacac9EXpaRufnpnGvpv+rq\nl33Ezf/5xWka2wZYVJbD33x2mVScE2ElK+0wa5XzbBFDaUY9plR90LvagTNtCdrTtqwiD5fHR0Pr\nAAD9Vie7XzhOY9sAqxYW8KWHb5WALcJOgnaYtUj5UhFjhbmpXBkcmfTalzQLmbmJV7+6+uzs3HuM\ndssw99XM5fOfWRKxnttidpO3gWHW0m1Fp9VQnCdnWCI2CrLTuHh5iCuDI4EqadeyOVzotBpSpHzm\ntFWVZJFi0PJ+Qw/vnu3G5nDz4D0VfOrOMimaIiJG3gqGkcfr47LFRmlBOjqt/NWK2CjMDX6ubbW7\nyUjTS3CZAZ1Ww5L5uQzaXAyPuPmzjy/g02vny9+piCiJLGHUcWUYj1eVJDQRU6HUILc53HKeHQZ3\nLysm22Tgrx9cxr0r5sZ6OGIWkO3xMGrplvKlIvYKg3T7cnt8jLi8cp4dBiuq8llRdXeshyFmEVlp\nh1Fr11j5UskcFzEUWGnf5K62XPcSInFJ0A6jlm4rGkWhxJwe66GIWSw1RUdmmp6evhuvtK12fzU0\nKWEqRKKRoB0mPp9KW4+NOflpU+6xK0S4FeSkcWVwBI/3+mtfct1LiMQlQTtMuvvtON1eSUITcaEw\nJxWfqtI7OHLd52R7XIjEJUE7TPydvebJebaIAwWT1CAf7/AlQVuIRCNBO0z8meOy0hbxINDt6wbn\n2rLSFiJxzZqgraoqb5y4zPtnu/Cpatifv7XbhgKUFpjC/txCTNVkGeQ2uwRtIRLVrLmn7XR7+elr\n53F7fMzJT+f+1aXcsaQoLPWBVVWlpctKQW6aNAgQcaFgkr7aVn8v7TTJHhci0cyalbbRoOMbf7aK\nD99WQnefnX//zTm+8sN3+NWRZuwj7hk995XBEexOD2WFssoW8SE1RUdWuuGGVdFke1yIxDVrgjZA\nidnElj++jWc+fyf3rynF6fLyi99fYuv/fYefvnb+hpm2oWiV82wRhwpyUukduv7al83uxmjQShcq\nIRLQrPypzc00suG+Kr79V3fx8IcqSTVo+e37bTzxwyM8d+BMIAiHKlC+VDLHRRwpzElDVcEycPUW\nudXhllW2EAlqVh/Aphl1/MEdZaxfXcq7Z7p59Wgr757p5t0z3Syen8PHb5/Hkvm5Qbv2tPjLl8pK\nW8SRiTXIi/NGq/SpqorV7qa0QKr2CZGIZnXQ9tNpNdy9vJi7lhVx+lIfr7zXwtnmfs4291NaYOLj\na+axelHBTdtttnRbycs0yupFxBV/BnnPhHNtp9uLx+vDJCVMhUhIErQnUBSF5ZV5LK/Mo6lziFeP\ntvL+uR7+5b/P/v/t3WtsVVWfx/Hv6WlPKz2F0vSUkaEgbWjGS+TiJTIZ6CTaYLBCLJe2A1ZDXyAx\nIohSIEEOtlZIDH1BAGmC0RTiDTFIVORxwJCplQeRKqWVUabDkMowbaWWUyotdM0LPBtOi70Iz9Oz\nDr/Pq7P3WiXrn//e/Pdl7b358OBJsu5PZer4kSEzxFsCF2lt62DiuORBHLlIT9ebQa7HvUTspqL9\nB8bePpRnZt7DrMx2/nL4NAe//5n39v/Ex5X/zb9OHMkj96UyPCHWeROavuwl4eZ6z2qfb9fb0ERs\npqLdB1/ibfxbVgYz/mUsB4428O/fnOazr/+HfX89zeS7/wF+v92t+9kSbmI9boZ5PSFvRdPjXiJ2\nU9HuJ+9tMTz+z3fw6IOpfFXzv+z962n+49gZp320iraEoRHDh/Dj6RY6L3UREx3lXB7XmbaInVS0\nBygm2k3mhH9kyviRfPdjE/sOn2ZIXDSJXk3skfAzYvht/OfpFhpb2hmZHO9cHtdENBE7qWj/SVEu\nFxMzfEzM8A32UET+0IhrvvY1Mjme8xeCrzDVmbaIjfos2l1dXfj9fk6cOIHH46GkpIQxY8YA0NjY\nyAsvvOD0raurY9myZeTn5wPQ3NxMTk4Ob775Junp6SxdupSmpiYAGhoaGD9+PGVlZX+LuESEnl/7\n0j1tEbv1WbS/+OILOjo6eO+996iurmbdunVs2bIFAJ/PR0VFBQBHjx6lrKyMuXPnAtDZ2cnLL79M\nXFyc828FC/Svv/5KQUEBK1euvOkBichVzrPav88gdx750pm2iJX6fI3pkSNHmDJlCgATJkygpqam\nRx9jDMXFxfj9ftxuNwDr168nLy+PlJSUHv03btzI/Pnzr9smIjePr9uz2ufbO3EB8XG6MyZioz6L\ndiAQwOu9+vUqt9vNpUuXQvrs37+fcePGkZaWBsCuXbtISkpyiv21mpubqaqqIicn50bHLiJ9iI1x\nMzwh9uqZdnsnQ+KicUfdkp8dELFen4fbXq+XtrY2Z7mrq4vo6NA/+/jjjykoKHCWP/zwQ1wuF1VV\nVdTV1VFUVMSWLVvw+Xzs3buX7Oxs54y8N8OHDyE6uu9+A+XzRd7jWZEYE0RmXH/vmEalJFDzX00M\nSxzChd8ukZgQe9PHEIl5gsiMKxJjgsiNq7s+i/akSZM4cOAA06dPp7q6moyMjB59ampqmDRpkrO8\nY8cO5/eTTz6J3+/H57syy7qqqopFixb1a3DnzvX8FvCN8vkSaGwc2Fe8wl0kxgSRGddgxDTc68EY\nOP7j/9Ha1kFyYtxNHUMk5gkiM65IjAkiL67eDkD6LNpZWVlUVlaSl5eHMYbS0lL27NnDhQsXyM3N\n5ZdffsHr9fb5Jayg+vp6UlNT+z96Ebkhwa991Z9ppcsYEjRzXMRafRbtqKgoXnnllZB16enpzu+k\npCR27979h38fnF0e9Mknnwx0jCJyA4IzyE82tAJ63EvEZpqNIhLhgs9qn/z5V0CPe4nYTEVbJML5\nEq8U7Z8br0woTdArTEWspaItEuE8MW6ShsZifl/W5XERe6loi9wCgve1QZfHRWymoi1yCwje1wY0\ne1zEYiraIreAFJ1pi0QEFW2RW0DwWW3QRDQRm6loi9wCgmfa7igXt8Xe/FcDi8jfh4q2yC0gJTEO\nF1dmjvf37YUiEn70fT6RW0BMtJt/GjOcIfokp4jVtAeL3CJeyp842EMQkRuky+MiIiKWUNEWERGx\nhIq2iIiIJVS0RURELKGiLSIiYgkVbREREUuoaIuIiFhCRVtERMQSKtoiIiKWUNEWERGxhIq2iIiI\nJVS0RURELOEyxpjBHoSIiIj0TWfaIiIillDRFhERsYSKtoiIiCVUtEVERCyhoi0iImIJFW0RERFL\nRA/2AP4Wurq68Pv9nDhxAo/HQ0lJCWPGjHHa9+/fz6ZNm4iOjmbWrFnMnTt3EEfbP52dnaxatYqG\nhgY6OjpYtGgRDz/8sNP+1ltv8cEHH5CUlATA2rVrSUtLG6zhDsgTTzyB1+sFYNSoUbz22mtOm425\n2rVrFx999BEAFy9epK6ujsrKSoYOHQrYmavvvvuO119/nYqKCk6dOsWKFStwuVyMGzeONWvWEBV1\n9fi/r/0vXFwbU11dHcXFxbjdbjweD+vXryc5OTmkf2/babi4Nqba2loWLlzIHXfcAUB+fj7Tp093\n+tqSJwiNa+nSpTQ1NQHQ0NDA+PHjKSsrC+lvQ67+NBOBPv/8c1NUVGSMMebo0aPmmWeecdo6OjrM\nI488YlpaWszFixdNTk6OaWxsHKyh9tvOnTtNSUmJMcaYc+fOmczMzJD2ZcuWmWPHjg3CyG7Mb7/9\nZmbOnHndNltzdS2/32/efffdkHW25aq8vNxkZ2ebOXPmGGOMWbhwofn666+NMcasXr3a7Nu3L6R/\nb/tfuOge07x580xtba0xxph33nnHlJaWhvTvbTsNF91jev/99822bdv+sL8NeTKmZ1xBLS0tZsaM\nGebs2bMh623I1Y2IyMvjR44cYcqUKQBMmDCBmpoap+3kyZOMHj2aYcOG4fF4uO+++zh8+PBgDbXf\nHn30UZ5//nkAjDG43e6Q9uPHj1NeXk5+fj5bt24djCH+KT/88APt7e0sWLCAgoICqqurnTZbcxV0\n7NgxfvrpJ3Jzc0PW25ar0aNHs3HjRmf5+PHjPPjggwBMnTqVr776KqR/b/tfuOge04YNG7jzzjsB\nuHz5MrGxsSH9e9tOw0X3mGpqavjyyy+ZN28eq1atIhAIhPS3IU/QM66gjRs3Mn/+fFJSUkLW25Cr\nGxGRRTsQCDiXRgDcbjeXLl1y2hISEpy2+Pj4HhtzOIqPj8fr9RIIBFi8eDFLliwJaX/sscfw+/28\n/fbbHDlyhAMHDgzSSAcmLi6OwsJCtm3bxtq1a3nxxRetz1XQ1q1befbZZ3usty1X06ZNIzr66p00\nYwwulwu4kpPz58+H9O9t/wsX3WMK/sf/7bffsn37dp5++umQ/r1tp+Gie0z33nsvy5cvZ8eOHaSm\nprJp06aQ/jbkCXrGBdDc3ExVVRU5OTk9+tuQqxsRkUXb6/XS1tbmLHd1dTlJ797W1tYWUhjC2Zkz\nZygoKGDmzJk8/vjjznpjDE899RRJSUl4PB4yMzOpra0dxJH239ixY5kxYwYul4uxY8eSmJhIY2Mj\nYHeuWltbqa+v56GHHgpZb3Ougq69f93W1ubcqw/qbf8LZ59++ilr1qyhvLzcmW8Q1Nt2Gq6ysrK4\n5557nN/dtzNb8wSwd+9esrOze1xxBDtzNRARWbQnTZrEwYMHAaiuriYjI8NpS09P59SpU7S0tNDR\n0cE333zDxIkTB2uo/dbU1MSCBQt46aWXmD17dkhbIBAgOzubtrY2jDEcOnTI2VnD3c6dO1m3bh0A\nZ8+eJRAI4PP5AHtzBXD48GEmT57cY73NuQq66667OHToEAAHDx7k/vvvD2nvbf8LV7t372b79u1U\nVFSQmprao7237TRcFRYW8v333wNQVVXF3XffHdJuY56CqqqqmDp16nXbbMzVQNhxWDVAWVlZVFZW\nkpeXhzGG0tJS9uzZw4ULF8jNzWXFihUUFhZijGHWrFmMGDFisIfcpzfeeIPW1lY2b97M5s2bAZgz\nZw7t7e3k5uaydOlSCgoK8Hg8TJ48mczMzEEecf/Mnj2blStXkp+fj8vlorS0lM8++8zqXAHU19cz\natQoZ/na7c/WXAUVFRWxevVqNmzYQFpaGtOmTQNg+fLlLFmy5Lr7Xzi7fPkyr776KrfffjvPPfcc\nAA888ACLFy92YrredhruZ6V+v5/i4mJiYmJITk6muLgYsDdP16qvr+9xcGVzrgZCX/kSERGxRERe\nHhcREYlEKtoiIiKWUNEWERGxhIq2iIiIJVS0RURELKGiLSIiYgkVbREREUuoaIuIiFji/wFjT0bp\nn939uAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c4ff780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lgbBO.res[\"all\"][\"values\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7507521452114979,\n",
       " 'max_depth': 9.876298947569682,\n",
       " 'min_child_weight': 30.49556775046322,\n",
       " 'min_split_gain': 0.09159674279901034,\n",
       " 'num_leaves': 30.128761469018812,\n",
       " 'reg_alpha': 0.09274254633966617,\n",
       " 'reg_lambda': 0.005176611637954099,\n",
       " 'subsample': 0.7027356589192597,\n",
       " 'subsample_freq': 1.1354253892533}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res[\"max\"][\"max_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699004375001968"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup = [key[0] for key, val in corr_mat.items() if val == 1.0]\n",
    "features_selected_20_less = [col_ for i, col_ in enumerate(features_selected) if i not in dup]\n",
    "\n",
    "X_num_train = data_train[features_selected_20_less].values\n",
    "X_num_val = data_val[features_selected_20_less].values\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "lgb_params =  {\n",
    "    \"nthread\": 8,\n",
    "    \"n_estimators\": 250, # 10000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 30,\n",
    "    \"colsample_bytree\": 0.7507521452114979,\n",
    "    \"subsample\": 0.7027356589192597,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"max_depth\": 10,\n",
    "    \"reg_alpha\": 0.09274254633966617,\n",
    "    \"reg_lambda\": 0.0051766116379540994,\n",
    "    \"min_split_gain\": 0.09159674279901034,\n",
    "    \"min_child_weight\": 30.49556775046322,\n",
    "    \"random_state\": 0,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "lg_clf = LightGBMWrapper(clf=LGBMClassifier, seed=0, params=lgb_params)\n",
    "lg_clf.train(X_num_train, y_train)\n",
    "pred_val = lg_clf.predict(X_num_val)\n",
    "roc_auc_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6037"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_train, data_val, X_num_train, X_num_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [key[0] for key, val in corr_mat.items() if val == 1.0]\n",
    "\n",
    "features_selected_20_less = [col_ for i, col_ in enumerate(features_selected) if i not in dup]\n",
    "\n",
    "X = data[features_selected_20_less].values\n",
    "y_data = y.TARGET.values\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "train_data = lgb.Dataset(data=X, label=y_data)\n",
    "n_folds = 5\n",
    "random_seed = 0\n",
    "\n",
    "def target_function(num_leaves,\n",
    "                    colsample_bytree,\n",
    "                    subsample,\n",
    "                    subsample_freq,\n",
    "                    max_depth,\n",
    "                    reg_alpha,\n",
    "                    reg_lambda,\n",
    "                    min_split_gain,\n",
    "                    min_child_weight):\n",
    "    global train_data, nfolds, random_seed\n",
    "    params = {\n",
    "        \"nthread\": 8,\n",
    "        \"n_estimators\": 2000,\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"random_state\": 0,\n",
    "        'metric':'auc',\n",
    "        \"silent\": -1,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "    params[\"num_leaves\"] = int(round(num_leaves))\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0.1)\n",
    "    params['subsample'] = max(min(subsample, 1), 0.1)\n",
    "    params['subsample_freq'] = int(round(subsample_freq))\n",
    "    params['max_depth'] = int(round(max_depth))\n",
    "    params['reg_alpha'] = max(reg_alpha, 0)\n",
    "    params['reg_lambda'] = max(reg_lambda, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =1000, metrics=['auc'])\n",
    "    return max(cv_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_depth |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample |   subsample_freq | \n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(\n",
    "    target_function,\n",
    "    {\n",
    "        \"num_leaves\": (28, 45),\n",
    "        \"colsample_bytree\": (.65, .99),\n",
    "        \"subsample\": (.65, .99),\n",
    "        \"subsample_freq\": (1, 3),\n",
    "        \"max_depth\": (6, 12),\n",
    "        \"reg_alpha\": (.0, .2),\n",
    "        \"reg_lambda\": (.0, .2),\n",
    "        \"min_split_gain\": (.0, .2),\n",
    "        \"min_child_weight\": (30, 45),\n",
    "    },\n",
    "    random_state=0)\n",
    "\n",
    "lgbBO.maximize(init_points=10, n_iter=50, acq='ei', xi=0.0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "181px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "789px",
    "left": "0px",
    "right": "1488px",
    "top": "138px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
