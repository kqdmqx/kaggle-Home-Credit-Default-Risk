{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe(path, dataframe):\n",
    "    np.save(path + \".data\", dataframe.values)\n",
    "    np.save(path + \".header\", dataframe.columns)\n",
    "    \n",
    "def load_dataframe(path):\n",
    "    data = np.load(path + \".data.npy\")\n",
    "    header = np.load(path + \".header.npy\")\n",
    "    return pd.DataFrame(data=data, columns=header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train blending validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_dataframe(\"./bindata/data_009\")\n",
    "data[\"SK_ID_CURR\"] = data.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "test = load_dataframe(\"./bindata/test_009\")\n",
    "test[\"SK_ID_CURR\"] = test.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "y = load_dataframe(\"./bindata/y_009\")\n",
    "y[\"SK_ID_CURR\"] = y.SK_ID_CURR.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "ydata_train = y[y.SK_ID_CURR < 130000]\n",
    "ydata_blending = y[(y.SK_ID_CURR >= 130000) & (y.SK_ID_CURR < 150000)]\n",
    "ydata_val = y[(y.SK_ID_CURR >= 150000) & (y.SK_ID_CURR < 170000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25803, 380), (17392, 380), (17182, 380))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_blending.shape, data_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single xgbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb0: data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "blending: 0.761223717838\n",
      "validate: 0.758524498285\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending0 = xgb_clf.predict(X_num_blending)\n",
    "pred_val0 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending0))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb1: data & nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "(25803, 429)\n",
      "(17392, 429)\n",
      "(17182, 429)\n",
      "blending: 0.761760124161\n",
      "validate: 0.76009622081\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\",\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name + \"_nmf5\"\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending1 = xgb_clf.predict(X_num_blending)\n",
    "pred_val1 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending1))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb2: data & 4wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n",
      "(25803, 906)\n",
      "(17392, 906)\n",
      "(17182, 906)\n",
      "blending: 0.763302570922\n",
      "validate: 0.761314749364\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending2 = xgb_clf.predict(X_num_blending)\n",
    "pred_val2 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending2))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb3: data & timestep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673\n",
      "(25803, 673)\n",
      "(17392, 673)\n",
      "(17182, 673)\n",
      "blending: 0.761386169203\n",
      "validate: 0.758360127963\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep1_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending3 = xgb_clf.predict(X_num_blending)\n",
    "pred_val3 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending3))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb4: data & timestep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2461\n",
      "(25803, 2461)\n",
      "(17392, 2461)\n",
      "(17182, 2461)\n",
      "blending: 0.762032413188\n",
      "validate: 0.761070800523\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending4 = xgb_clf.predict(X_num_blending)\n",
    "pred_val4 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending4))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking\n",
    "\n",
    "https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blending_stack = (\n",
    "    pred_blending0,\n",
    "    pred_blending1,\n",
    "    pred_blending2,\n",
    "    pred_blending3,\n",
    "    pred_blending4\n",
    ")\n",
    "\n",
    "val_stack = (\n",
    "    pred_val0,\n",
    "    pred_val1,\n",
    "    pred_val2,\n",
    "    pred_val3,\n",
    "    pred_val4\n",
    ")\n",
    "\n",
    "blending_aucs = [roc_auc_score(y_blending, pred_) for pred_ in blending_stack]\n",
    "val_aucs = [roc_auc_score(y_val, pred_) for pred_ in val_stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blending</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761224</td>\n",
       "      <td>0.758524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.761760</td>\n",
       "      <td>0.760096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763303</td>\n",
       "      <td>0.761315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761386</td>\n",
       "      <td>0.758360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.762032</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764013</td>\n",
       "      <td>0.761811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      blending       val\n",
       "0     0.761224  0.758524\n",
       "1     0.761760  0.760096\n",
       "2     0.763303  0.761315\n",
       "3     0.761386  0.758360\n",
       "4     0.762032  0.761071\n",
       "mean  0.764013  0.761811"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_data = pd.DataFrame({\n",
    "    \"blending\": blending_aucs,\n",
    "    \"val\": val_aucs\n",
    "})\n",
    "\n",
    "metric_data.loc[\"mean\"] = {\n",
    "    \"blending\": roc_auc_score(y_blending, sum(blending_stack)),\n",
    "    \"val\": roc_auc_score(y_val, sum(val_stack))\n",
    "}\n",
    "\n",
    "metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762250054132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_pred_bld = np.array(blending_stack).T\n",
    "X_pred_val = np.array(val_stack).T\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_pred_bld, y_blending)\n",
    "pred_bld_val = clf.predict_proba(X_pred_val)[:, 1]\n",
    "print(roc_auc_score(y_val, pred_bld_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74069456,  1.90968882,  2.18610268,  1.44764993,  3.00154614])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_weight = clf.coef_[0]\n",
    "pred_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submmit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub0 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./result/submission-010-sub0\", pred_sub0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\",\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name + \"_nmf5\"\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub1 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub1\", pred_sub1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub2 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub2\", pred_sub2)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep1_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub3 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub3\", pred_sub3)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./result/X_pred_bld-010\", X_pred_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./result/X_pred_val-010\", X_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-35a7826b0813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "del data_train\n",
    "del data_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307511"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.SK_ID_CURR.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data.astype(np.float32)\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name).astype(np.float32)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "del data_train\n",
    "gc.collect()\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "\n",
    "del X_num_train\n",
    "gc.collect()\n",
    "\n",
    "data_val = test.astype(np.float32)\n",
    "del test\n",
    "gc.collect()\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name).astype(np.float32)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "X_num_val = data_val[features].values\n",
    "pred_sub4 = xgb_clf.predict(X_num_val)\n",
    "np.save(\"./result/submission-010-sub4\", pred_sub4)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "907px",
    "left": "0px",
    "right": "1592px",
    "top": "107px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
