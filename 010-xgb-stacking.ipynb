{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe(path, dataframe):\n",
    "    np.save(path + \".data\", dataframe.values)\n",
    "    np.save(path + \".header\", dataframe.columns)\n",
    "    \n",
    "def load_dataframe(path):\n",
    "    data = np.load(path + \".data.npy\")\n",
    "    header = np.load(path + \".header.npy\")\n",
    "    return pd.DataFrame(data=data, columns=header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train blending validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_dataframe(\"./bindata/data_009\")\n",
    "data[\"SK_ID_CURR\"] = data.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "test = load_dataframe(\"./bindata/test_009\")\n",
    "test[\"SK_ID_CURR\"] = test.SK_ID_CURR.astype(\"int\")\n",
    "\n",
    "y = load_dataframe(\"./bindata/y_009\")\n",
    "y[\"SK_ID_CURR\"] = y.SK_ID_CURR.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "ydata_train = y[y.SK_ID_CURR < 130000]\n",
    "ydata_blending = y[(y.SK_ID_CURR >= 130000) & (y.SK_ID_CURR < 150000)]\n",
    "ydata_val = y[(y.SK_ID_CURR >= 150000) & (y.SK_ID_CURR < 170000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25803, 380), (17392, 380), (17182, 380))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_blending.shape, data_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single xgbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb0: data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "blending: 0.761223717838\n",
      "validate: 0.758524498285\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending0 = xgb_clf.predict(X_num_blending)\n",
    "pred_val0 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending0))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb1: data & nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "(25803, 429)\n",
      "(17392, 429)\n",
      "(17182, 429)\n",
      "blending: 0.761760124161\n",
      "validate: 0.76009622081\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\",\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name + \"_nmf5\"\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending1 = xgb_clf.predict(X_num_blending)\n",
    "pred_val1 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending1))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb2: data & 4wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n",
      "(25803, 906)\n",
      "(17392, 906)\n",
      "(17182, 906)\n",
      "blending: 0.763302570922\n",
      "validate: 0.761314749364\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending2 = xgb_clf.predict(X_num_blending)\n",
    "pred_val2 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending2))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb3: data & timestep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673\n",
      "(25803, 673)\n",
      "(17392, 673)\n",
      "(17182, 673)\n",
      "blending: 0.761386169203\n",
      "validate: 0.758360127963\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep1_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending3 = xgb_clf.predict(X_num_blending)\n",
    "pred_val3 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending3))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb4: data & timestep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2461\n",
      "(25803, 2461)\n",
      "(17392, 2461)\n",
      "(17182, 2461)\n",
      "blending: 0.762032413188\n",
      "validate: 0.761070800523\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.SK_ID_CURR < 130000]\n",
    "data_blending = data[(data.SK_ID_CURR >= 130000) & (data.SK_ID_CURR < 150000)]\n",
    "data_val = data[(data.SK_ID_CURR >= 150000) & (data.SK_ID_CURR < 170000)]\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_blending = data_blending.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_blending = data_blending[features].values\n",
    "X_num_val = data_val[features].values\n",
    "\n",
    "print(X_num_train.shape)\n",
    "print(X_num_blending.shape)\n",
    "print(X_num_val.shape)\n",
    "\n",
    "y_train = ydata_train.TARGET.values\n",
    "y_blending = ydata_blending.TARGET.values\n",
    "y_val = ydata_val.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 250\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_blending4 = xgb_clf.predict(X_num_blending)\n",
    "pred_val4 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "print(\"blending:\", roc_auc_score(y_blending, pred_blending4))\n",
    "print(\"validate:\", roc_auc_score(y_val, pred_val4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking\n",
    "\n",
    "https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blending_stack = (\n",
    "    pred_blending0,\n",
    "    pred_blending1,\n",
    "    pred_blending2,\n",
    "    pred_blending3,\n",
    "    pred_blending4\n",
    ")\n",
    "\n",
    "val_stack = (\n",
    "    pred_val0,\n",
    "    pred_val1,\n",
    "    pred_val2,\n",
    "    pred_val3,\n",
    "    pred_val4\n",
    ")\n",
    "\n",
    "blending_aucs = [roc_auc_score(y_blending, pred_) for pred_ in blending_stack]\n",
    "val_aucs = [roc_auc_score(y_val, pred_) for pred_ in val_stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blending</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761224</td>\n",
       "      <td>0.758524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.761760</td>\n",
       "      <td>0.760096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763303</td>\n",
       "      <td>0.761315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761386</td>\n",
       "      <td>0.758360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.762032</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764013</td>\n",
       "      <td>0.761811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      blending       val\n",
       "0     0.761224  0.758524\n",
       "1     0.761760  0.760096\n",
       "2     0.763303  0.761315\n",
       "3     0.761386  0.758360\n",
       "4     0.762032  0.761071\n",
       "mean  0.764013  0.761811"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_data = pd.DataFrame({\n",
    "    \"blending\": blending_aucs,\n",
    "    \"val\": val_aucs\n",
    "})\n",
    "\n",
    "metric_data.loc[\"mean\"] = {\n",
    "    \"blending\": roc_auc_score(y_blending, sum(blending_stack)),\n",
    "    \"val\": roc_auc_score(y_val, sum(val_stack))\n",
    "}\n",
    "\n",
    "metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762250054132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_pred_bld = np.array(blending_stack).T\n",
    "X_pred_val = np.array(val_stack).T\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_pred_bld, y_blending)\n",
    "pred_bld_val = clf.predict_proba(X_pred_val)[:, 1]\n",
    "print(roc_auc_score(y_val, pred_bld_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74069456,  1.90968882,  2.18610268,  1.44764993,  3.00154614])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_weight = clf.coef_[0]\n",
    "pred_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submmit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub0 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./result/submission-010-sub0\", pred_sub0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\",\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name + \"_nmf5\"\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub1 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub1\", pred_sub1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_wide_009\",\n",
    "    \"buro_full_wide_009\",\n",
    "    \"pos_bal_wide_009\",\n",
    "    \"cc_bal_wide_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub2 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub2\", pred_sub2)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep1_009\",\n",
    "    \"pos_bal_timestep1_009\",\n",
    "    \"cc_bal_timestep1_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = data_train[features].values\n",
    "X_num_val = data_val[features].values\n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "pred_sub3 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub3\", pred_sub3)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./result/X_pred_bld-010\", X_pred_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./result/X_pred_val-010\", X_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2461\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-147f21152cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mX_num_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mX_num_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2724\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take\u001b[1;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[0;32m   2780\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_take'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2782\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2784\u001b[0m         new_data = self._data.take(indices,\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4433\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4435\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   4422\u001b[0m         \"\"\"\n\u001b[0;32m   4423\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4424\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4426\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4096\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4097\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4098\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4099\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4103\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   5067\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5068\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[1;32m-> 5069\u001b[1;33m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[0;32m   5070\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5071\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   5090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5091\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5092\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5093\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "data_train = data\n",
    "data_val = test\n",
    "\n",
    "for source_name in (\n",
    "    \"buro_bal_timestep2_009\",\n",
    "    \"pos_bal_timestep2_009\",\n",
    "    \"cc_bal_timestep2_009\"\n",
    "):\n",
    "    target_name = \"./bindata/\" + source_name\n",
    "    nmf_data = load_dataframe(target_name)\n",
    "    nmf_data[\"SK_ID_CURR\"] = nmf_data.SK_ID_CURR.astype(\"int\")\n",
    "    nmf_data.columns = [\"{}_{}\".format(source_name, col_) if col_ != \"SK_ID_CURR\" else col_ for col_ in nmf_data.columns]\n",
    "    data_train = data_train.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    data_val = data_val.merge(right=nmf_data, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "features = list(data_train.columns)\n",
    "features.remove(\"SK_ID_CURR\")\n",
    "print(len(features))\n",
    "\n",
    "X_num_train = \n",
    "y_train = y.TARGET.values\n",
    "\n",
    "xgb_params = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"booster\": \"gbtree\",\n",
    "     \"eval_metric\": \"auc\",\n",
    "     \"nthread\": 8,\n",
    "     \"eta\": 0.025,\n",
    "     \"max_depth\": 6,\n",
    "     \"min_child_weight\": 19,\n",
    "     \"gamma\": 0,\n",
    "     \"subsample\": 0.8,\n",
    "     \"colsample_bytree\": 0.632,\n",
    "     \"alpha\": 0,\n",
    "     \"lambda\": 0.05,\n",
    "     \"nrounds\": 2000\n",
    "}\n",
    "\n",
    "xgb_clf = XgbWrapper(params=xgb_params)\n",
    "xgb_clf.train(X_num_train, y_train)\n",
    "\n",
    "del X_num_train\n",
    "gc.collect()\n",
    "\n",
    "X_num_val = data_val[features].values\n",
    "pred_sub4 = xgb_clf.predict(X_num_val)\n",
    "\n",
    "np.save(\"./result/submission-010-sub4\", pred_sub4)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "907px",
    "left": "0px",
    "right": "1592px",
    "top": "107px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
